{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from data.preparation import *\n",
    "from data.transforms import *\n",
    "from data.dataset import *\n",
    "\n",
    "from model_zoo.models import define_model\n",
    "\n",
    "from training.main import k_fold\n",
    "\n",
    "from util.torch import init_distributed\n",
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    init_neptune\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"source\"] == \"extracted\", \"split\"] = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen = prepare_gen_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gen_a = prepare_gen_data(DATA_PATH, img_folder=\"gen_andrija/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df, df_gen, df_gen_a], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='chart-type', hue=\"split\", data=df)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(augment=True, strength=3, resize=(256, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ClsDataset(df, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(range(len(dataset))):\n",
    "#     i = np.random.choice(len(dataset))\n",
    "    \n",
    "#     plt.figure(figsize=(15, 15))\n",
    "#     for k in range(9):\n",
    "#         plt.subplot(3, 3, k + 1)\n",
    "#         img, y, _ = dataset[i]\n",
    "\n",
    "#         plt.imshow(img.numpy().transpose(1, 2, 0))\n",
    "#         plt.axis(False)\n",
    "# #     plt.title(CLASSES[int(y)])\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    i = np.random.choice(len(dataset))\n",
    "    img, y, _ = dataset[i]\n",
    "    \n",
    "    plt.imshow(img.numpy().transpose(1, 2, 0))\n",
    "    plt.title(CLASSES[int(y)])\n",
    "    plt.show()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model(\"tf_efficientnetv2_b0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_aux = model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"\n",
    "    save_weights = True\n",
    "\n",
    "    # Images\n",
    "    img_folder = \"train/images/\"\n",
    "    window = img_folder.endswith(\"_w/\")\n",
    "    aug_strength = 3\n",
    "    resize = (256, 384)\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = None\n",
    "    selected_folds = [0]\n",
    "\n",
    "    # Model\n",
    "    name = \"tf_efficientnetv2_b0\"  # \"eca_nfnet_l2\"  # \"tf_efficientnetv2_s\" \"eca_nfnet_l1\"\n",
    "    pretrained_weights = None\n",
    "    num_classes = len(CLASSES)\n",
    "    num_classes_aux = 0\n",
    "    n_channels = 3\n",
    "    reduce_stride = False\n",
    "    drop_rate = 0.1\n",
    "    drop_path_rate = 0.1\n",
    "    use_gem = True\n",
    "    syncbn = False\n",
    "\n",
    "    # Training\n",
    "    loss_config = {\n",
    "        \"name\": \"ce\",\n",
    "        \"smoothing\": 0.0,\n",
    "        \"activation\": \"softmax\",\n",
    "        \"aux_loss_weight\": 0.,\n",
    "        \"pos_weight\": None,\n",
    "        \"activation_aux\": \"softmax\",\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 16,\n",
    "        \"val_bs\": 32,\n",
    "        \"mix\": \"cutmix\",\n",
    "        \"mix_proba\": 1,\n",
    "        \"mix_alpha\": 4.0,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"additive_mix\": False,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"Ranger\",\n",
    "        \"lr\": 5e-4,\n",
    "        \"warmup_prop\": 0.0,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.0,\n",
    "        \"weight_decay\": 0,  # 1e-2,\n",
    "    }\n",
    "\n",
    "    epochs = 1\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 200\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None\n",
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not DEBUG:\n",
    "#     log_folder = prepare_log_folder(LOG_PATH)\n",
    "#     print(f\"Logging results to {log_folder}\")\n",
    "#     config_df = save_config(Config, log_folder + \"config.json\")\n",
    "#     create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "# #     run = init_neptune(Config, log_folder)\n",
    "\n",
    "# df = prepare_data(DATA_PATH, DATA_PATH + Config.img_folder)\n",
    "# # df_gen = prepare_gen_data(DATA_PATH)\n",
    "# # df = pd.concat([df, df_gen], ignore_index=True)\n",
    "\n",
    "# # df= df.sample(1000).reset_index(drop=True)\n",
    "\n",
    "# # df['cancer'] = (df['BIRADS'] <= 0).astype(int)\n",
    "# # df = df.dropna(axis=0).reset_index(drop=True)\n",
    "# # df = df.head(10000) if DEBUG else df\n",
    "# config = Config\n",
    "# init_distributed(config)\n",
    "\n",
    "# preds = k_fold(config, df, log_folder=log_folder, run=run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_FOLDERS = [\n",
    "    \"../logs/2023-05-22/47/\",\n",
    "    \"../logs/2023-05-22/44/\",\n",
    "#     \"../logs/2023-05-22/45/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split'] == \"val\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = np.mean([\n",
    "    np.load(f + \"pred_val.npy\") for f in EXP_FOLDERS\n",
    "], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['pred'] = pred_val.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plots import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_val['pred'], df_val['target'], display_labels=CLASSES, normalize=None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f\"Acc = {(df_val['pred'] == df_val['target']).mean() :.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_err = df_val[df_val['pred'] != df_val['target']].reset_index(drop=True)\n",
    "\n",
    "# dataset = ClsDataset(df_err, get_transfos(augment=False, resize=(256, 384)))\n",
    "\n",
    "# for i in tqdm(range(len(dataset))):\n",
    "#     img, y, _ = dataset[i]\n",
    "    \n",
    "#     plt.imshow(img.numpy().transpose(1, 2, 0))\n",
    "#     plt.title(f\"GT  {CLASSES[int(y)]} - PRED {CLASSES[df_err.pred[i]]}\")\n",
    "#     plt.show()\n",
    "\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.main import kfold_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = kfold_inference(df_val, EXP_FOLDERS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['pred_inf'] = pred_val.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(df_val['pred_inf'], df_val['target'], display_labels=CLASSES, normalize=None)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f\"Acc = {(df_val['pred_inf'] == df_val['target']).mean() :.4f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
