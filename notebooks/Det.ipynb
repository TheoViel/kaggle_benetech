{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import plot_annotated_image, plot_sample\n",
    "from util.torch import seed_everything\n",
    "from util.yolo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df_train.csv')\n",
    "df_text = pd.read_csv('../input/texts.csv')\n",
    "df_target = pd.read_csv('../input/y_train.csv')\n",
    "df_elt = pd.read_csv('../input/elements.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED = 42\n",
    "# seed_everything(SEED)\n",
    "\n",
    "# split = {}\n",
    "# for i in range(len(df)):\n",
    "#     split[df['id'][i]] = \"train\"\n",
    "\n",
    "#     if df['source'][i] == \"extracted\":\n",
    "#         split[df['id'][i]] = \"val\"\n",
    "        \n",
    "#         if df['chart-type'][i] == \"horizontal_bar\":\n",
    "#             if np.random.random() > 0.3:\n",
    "#                 split[df['id'][i]] = \"train\"\n",
    "#     else:\n",
    "#         if df['chart-type'][i] == \"dot\":\n",
    "#             if np.random.random() < 0.2:\n",
    "#                 split[df['id'][i]] = \"val\"\n",
    "                \n",
    "# df_split = pd.DataFrame.from_dict(split, orient=\"index\").reset_index()\n",
    "# df_split.columns = ['id', 'split']\n",
    "# df_split.to_csv('../input/df_split.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = df['source'].map({\"generated\": \"train\", \"extracted\": \"val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_split = pd.read_csv('../input/df_split.csv')\n",
    "# df = df.merge(df_split)\n",
    "\n",
    "# sns.countplot(x=\"chart-type\", hue=\"split\", data=df)\n",
    "# # plt.yscale('log')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"chart-type\", hue=\"source\", data=df)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['source'] != \"generated\"].head()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALIES = [\n",
    "    # DUPLICATED STUFF\n",
    "    'ae686738e744', 'c76f6d0d5239', '760c3fa4e3d9', 'c0c1f4046222', '3e568d136b85', '913447978a74', '2ff071a45cce', 'a9a07d74ee31',\n",
    "    # MISSING or MISLABELED TICKS ANNOTS\n",
    "    \"36079df3b5b2\", \"3968efe9cbfc\", \"6ce4bc728dd5\", \"733b9b19e09a\", \"aa9df520a5f2\", \"d0cf883b1e13\",\n",
    "    # WEIRD\n",
    "    \"9f6b7c57e6cd\", \"e1034ff92655\", \"e796b10718bd\", \"f8bdbaf0b97d\", \"3ef41bbc82c3\", \"73cfbba65962\", \"872d1be39bae\", \"3ef41bbc82c3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isin(ANOMALIES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = np.random.choice(df[df['chart-type'] == \"dot\"].id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = '6f36d53ecec8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_annotated_image(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHART_TYPES = [\n",
    "#     \"vertical_bar\",\n",
    "#     \"horizontal_bar\",\n",
    "    \"dot\",\n",
    "#     \"line\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "CLASSES = [\n",
    "#     \"chart\",\n",
    "#     \"text\",\n",
    "#     \"tick\",\n",
    "    \"point\",\n",
    "]\n",
    "\n",
    "USE_GENERATED = True\n",
    "\n",
    "VERSION = 13\n",
    "\n",
    "df = df[df['chart-type'].isin(CHART_TYPES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['source'] == \"extracted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.merge(df_target.groupby('id').agg(list), on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['y'] = df['y'].apply(lambda x: np.min(np.array(x).astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['x'] = df['x'].apply(lambda x: np.min(np.array(x).astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['y'] < 0].id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.countplot(x=np.clip(df.y.values // 10, -10, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_PATH = '../yolov7/'\n",
    "DATA_PATH = '../input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {k: i for i, k in enumerate(CLASSES)}\n",
    "label_dict\n",
    "\n",
    "#(1) image file path\n",
    "yolo_train_img_dir = f'{DATA_PATH}/v{VERSION}/images/train/'\n",
    "yolo_valid_img_dir = f'{DATA_PATH}/v{VERSION}/images/valid/'\n",
    "\n",
    "#(2) label file path\n",
    "yolo_train_label_dir = f'{DATA_PATH}/v{VERSION}/labels/train/'\n",
    "yolo_valid_label_dir = f'{DATA_PATH}/v{VERSION}/labels/valid/'\n",
    "\n",
    "#(3) config file path\n",
    "yaml_file = f'{YOLO_PATH}/data_{VERSION}.yaml'\n",
    "\n",
    "os.makedirs(yolo_train_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_label_dir, exist_ok=True)\n",
    "\n",
    "shutil.rmtree(yolo_train_img_dir)\n",
    "shutil.rmtree(yolo_valid_img_dir)\n",
    "shutil.rmtree(yolo_train_label_dir)\n",
    "shutil.rmtree(yolo_valid_label_dir)\n",
    "\n",
    "os.makedirs(yolo_train_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_label_dir, exist_ok=True)\n",
    "\n",
    "yolo_train_img_dir, yolo_valid_img_dir, yolo_train_label_dir, yolo_valid_label_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_text[~df_text['axis'].isna()].reset_index(drop=True)  # ignore titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfts = {}\n",
    "for id_, dfg in tqdm(df_text.groupby('chart_id')):\n",
    "    dfts[id_] = dfg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfes = {}\n",
    "for id_, dfg in tqdm(df_elt.groupby('chart_id')):\n",
    "    dfes[id_] = dfg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['split'] = df['source'].map({\"generated\": \"train\", \"extracted\": \"val\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"chart\", \"text\", \"tick\", \"point\"]\n",
    "\n",
    "for i, (id_, dfg) in tqdm(enumerate(df.groupby('id')), total=len(df)):    \n",
    "#     id_ = 'e93bed1228d6'\n",
    "#     dfg = df[df['id'] == id_]\n",
    "\n",
    "    img_file = f'../input/train/images/{id_}.jpg'\n",
    "    src = dfg['source'].values[0]\n",
    "    split = dfg['split'].values[0]\n",
    "\n",
    "    if split == 'train':\n",
    "        yolo_img_dir = yolo_train_img_dir\n",
    "        yolo_label_dir = yolo_train_label_dir\n",
    "    else:\n",
    "        yolo_img_dir = yolo_valid_img_dir\n",
    "        yolo_label_dir = yolo_valid_label_dir\n",
    "\n",
    "#     # Extract boxes\n",
    "    try:\n",
    "        dft = dfts[id_]\n",
    "        dfe = dfes[id_]\n",
    "    except KeyError:\n",
    "#         print(\"Error\")\n",
    "        continue\n",
    "\n",
    "    boxes = extract_bboxes_2(dfg, dft, dfe, dfg['img_h'].values[0], dfg['img_w'].values[0])\n",
    "    boxes = [b for i, b in enumerate(boxes) if labels[i] in CLASSES]\n",
    "\n",
    "    if SAVE:\n",
    "        # Copy image\n",
    "        dst_file = f'{yolo_img_dir}/{id_}.jpg'\n",
    "        shutil.copyfile(img_file, dst_file)\n",
    "\n",
    "        # Save boxes\n",
    "        file_name = f'{yolo_label_dir}/{id_}.txt'\n",
    "        assert len(boxes) == len(CLASSES)\n",
    "\n",
    "        written = []\n",
    "        with open(file_name, 'w') as f:\n",
    "            for c, boxes_c in enumerate(boxes):\n",
    "                for box in boxes_c:\n",
    "                    str_bbox = ' '.join([str(c)] + [f\"{b:.4g}\" for b in box])\n",
    "                    if str_bbox not in written:\n",
    "                        f.write(str_bbox)\n",
    "                        f.write('\\n')\n",
    "                        written.append(str_bbox)\n",
    "\n",
    "                \n",
    "    if PLOT or not (i % 10000):\n",
    "        img = cv2.imread(img_file)\n",
    "        plot_sample(img, boxes)\n",
    "        plt.title(f\"{id_} - {src} {dfg['chart-type'].values[0]}\")\n",
    "        plt.show()\n",
    "    \n",
    "#     if i >= 10:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.boxes import Boxes\n",
    "from util.plots import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {i: CLASSES.index(labels[i]) if labels[i] in CLASSES else -1 for i in range(len(labels))}\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GENERATED:\n",
    "    \n",
    "    EXTRA_DATA_PATHS = [\n",
    "        (\"../input/scatter/imgs_r/\", \"../input/scatter/preds_final_2/\"),\n",
    "        (\"../input/scatter/imgs_r_v2/\", \"../input/scatter/preds_v2_final/\"),\n",
    "        (\"../input/scatter/imgs_r_v3/\", \"../input/scatter/preds_v3_final/\"),\n",
    "    ]\n",
    "\n",
    "    for img_path, gt_path in EXTRA_DATA_PATHS:\n",
    "        for file in tqdm(sorted(os.listdir(img_path))):\n",
    "#             img = cv2.imread(img_path + file)\n",
    "            shutil.copyfile(img_path + file, yolo_train_img_dir + file)\n",
    "#             break\n",
    "\n",
    "        for file in tqdm(sorted(os.listdir(gt_path))):\n",
    "            with open(gt_path + file, 'r') as f:\n",
    "                boxes = [b[:-1] for b in f.readlines()]\n",
    "                classes = [int(b[:1]) for b in boxes]\n",
    "                boxes = [b[1:] for b in boxes]\n",
    "                \n",
    "#             break\n",
    "#             boxes_ = [b for b, c in zip(boxes, classes) if mapping[c] >= 0]\n",
    "#             preds = Boxes(np.array([b.strip().split(' ') for b in boxes_]).astype(float), img.shape,)['pascal_voc']\n",
    "#             plot_results(\n",
    "#                 img,\n",
    "#                 [[], [], [], preds],\n",
    "#                 figsize=(12, 7),\n",
    "#                 show=True\n",
    "#             )\n",
    "    \n",
    "            with open(yolo_train_label_dir + file, 'w') as f:\n",
    "                for c, box in zip(classes, boxes):\n",
    "                    new_c = mapping[c]\n",
    "                    if new_c == -1:\n",
    "                        continue\n",
    "                    str_bbox = str(new_c) + box\n",
    "    #                 print(str_bbox)\n",
    "                    f.write(str_bbox)\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump config file\n",
    "data_yaml = dict(\n",
    "    train=yolo_train_img_dir,\n",
    "    val=yolo_valid_img_dir,\n",
    "    nc=len(CLASSES),\n",
    "    names=CLASSES\n",
    ")\n",
    "\n",
    "print(data_yaml)\n",
    "\n",
    "with open(yaml_file, 'w') as outfile:\n",
    "    yaml.dump(data_yaml, outfile, default_flow_style=True)\n",
    "\n",
    "yaml_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from globox import AnnotationSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = AnnotationSet.from_yolo_v5(\n",
    "    folder=f\"{DATA_PATH}/v{VERSION}/labels/valid/\",\n",
    "    image_folder=f\"{DATA_PATH}/v{VERSION}/images/valid/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.show_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{DATA_PATH}/v{VERSION}/annotations/', exist_ok=True)\n",
    "yolo.save_coco(f\"{DATA_PATH}/v{VERSION}/annotations/val2017.json\", auto_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(f\"{DATA_PATH}/v{VERSION}/images/valid/\", f\"{DATA_PATH}/v{VERSION}/val2017\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = AnnotationSet.from_yolo_v5(\n",
    "    folder=f\"{DATA_PATH}/v{VERSION}/labels/train/\",\n",
    "    image_folder=f\"{DATA_PATH}/v{VERSION}/images/train/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.show_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.save_coco(f\"{DATA_PATH}/v{VERSION}/annotations/train2017.json\", auto_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(f\"{DATA_PATH}/v{VERSION}/images/train/\", f\"{DATA_PATH}/v{VERSION}/train2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(f\"{DATA_PATH}/v{VERSION}/train2017\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(f\"{DATA_PATH}/v{VERSION}/val2017\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(glob.glob(f\"{DATA_PATH}/v{VERSION}/train2017/*\")):\n",
    "    try:\n",
    "        assert file.endswith('.jpg') or file.endswith('.png')\n",
    "        assert cv2.imread(file) is not None\n",
    "    except:\n",
    "#         os.remove(file)\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
