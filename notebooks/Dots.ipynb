{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook contains the dot pipeline.\n",
    "\n",
    "**TODO :**\n",
    "- better model\n",
    "- Use CACHED for xlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-index --find-links=../input/cached addict terminaltables pycocotools mmcv_full mmdet\n",
    "# !pip install -U torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U openmim\n",
    "# mim install mmengine\n",
    "# mim install mmcv==1.7.1 mmdet==2.28.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "mmcv.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmdet \n",
    "mmdet.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from inference.yolox import retrieve_yolox_model, predict, YoloXWrapper\n",
    "from inference.utils import get_transfos, InferenceDataset\n",
    "from util.metrics import *\n",
    "from util.boxes import Boxes\n",
    "\n",
    "from post_process.retrieve import retrieve_missing_boxes\n",
    "from post_process.in_graph import post_process_preds_dots\n",
    "from post_process.dots import constraint_size, restrict_labels_x, assign_dots, cluster_on_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v13\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df_train.csv')\n",
    "df_text = pd.read_csv('../input/texts.csv')\n",
    "df_target = pd.read_csv('../input/y_train.csv')\n",
    "df_elt = pd.read_csv('../input/elements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isin(ANOMALIES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv('../input/df_split.csv')\n",
    "df = df.merge(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"dot\"]\n",
    "df = df[df['chart-type'].isin(CLASSES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df_test = pd.DataFrame({\"path\": glob.glob('../input/dots/*')})\n",
    "df_test['id'] = df_test['path'].apply(lambda x: Path(x).stem)\n",
    "df_test['source'] = \"extracted\"\n",
    "df_test['chart-type'] = \"dot\"\n",
    "df_test['gt_path'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "    \n",
    "#     name = \"benetech_1_m_1\"\n",
    "    name = \"benetech_1_l_1\"\n",
    "    cfg = f\"../yolox/exps/{name}.py\"\n",
    "    ckpt = f\"../yolox/YOLOX_outputs/{name}/best_ckpt.pth\"\n",
    "#     version = \"v11_sim\"\n",
    "    version = \"v13\"\n",
    "    labels = [\"point\"]\n",
    "\n",
    "    size = (1024, 1024)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = 0.1\n",
    "    iou_thresh = 0.1\n",
    "    max_per_img = 500\n",
    "    min_per_img = 1\n",
    "    \n",
    "    val_bs = 1  # if size[0] > 1024 else 16\n",
    "    device = \"cuda\"\n",
    "    \n",
    "config_marker = Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrieve_yolox_model(config_marker.cfg, config_marker.ckpt)\n",
    "model = YoloXWrapper(model, config_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER = \"../output/weights/dot/\"\n",
    "# os.makedirs(FOLDER, exist_ok=True)\n",
    "# name = Config.weights.split('/')[-3]\n",
    "\n",
    "# cp = torch.load(Config.weights)\n",
    "\n",
    "# import yaml\n",
    "# with open(FOLDER + name + '_cfg.yml', 'w') as outfile:\n",
    "#     yaml.dump(cp['model'].yaml, outfile)\n",
    "    \n",
    "# from util.torch import save_model_weights\n",
    "# torch.save(cp['model'].state_dict(), FOLDER + name + \"_weights.pt\")\n",
    "\n",
    "# print('-> Saved config to', FOLDER + name + '_cfg.yml')\n",
    "# print('-> Saved weight to', FOLDER + name + '_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert os.path.exists(Config.weights), \"Weights do not exist\"\n",
    "# assert os.path.exists(Config.cfg), \"Config does not exist\"\n",
    "\n",
    "# model = retrieve_model_robust(Config, '../yolov7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector  # depend heavily on mmcv\n",
    "\n",
    "wdir = '../input/cached/work_dirs'\n",
    "config_file = wdir + '/custom.py'\n",
    "checkpoint_file = wdir + '/cascade_rcnn_swin-t_fpn_LGF_VCE_PCE_coco_focalsmoothloss/checkpoint.pth'\n",
    "\n",
    "cached_model = init_detector(config_file, checkpoint_file, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart_types = [\"dot\"]\n",
    "# classes = ['chart', 'text', 'tick', 'point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION = \"v3\"\n",
    "\n",
    "# df_val = df[df['split'] == \"val\"].reset_index(drop=True)\n",
    "# df_val['path'] = f'../input/{VERSION}/images/valid/' + df_val['id'] + '.jpg'\n",
    "# df_val['gt_path'] = f'../input/{VERSION}/labels/valid/' + df_val['id'] + '.txt'\n",
    "# df_val_ = df_val.copy()\n",
    "\n",
    "# for t in chart_types:\n",
    "#     print(f'\\n-> Chart type : {t}\\n')\n",
    "#     df_val = df_val_[df_val_['chart-type'] == t].reset_index(drop=True).head(100)\n",
    "\n",
    "#     transforms = get_transfos(size=Config.size)\n",
    "#     dataset = InferenceDataset(df_val, transforms)\n",
    "\n",
    "#     meter, _ = predict(model, dataset, Config)\n",
    "#     for i, p in enumerate(meter.preds):\n",
    "#         p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))\n",
    "\n",
    "#     scores = {c: [] for c in classes}\n",
    "#     for idx in tqdm(range(len(dataset))):\n",
    "#         img, gt, shape = dataset[idx]\n",
    "\n",
    "#         gt = Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\")['pascal_voc']\n",
    "#         gt = [gt[dataset.classes[idx] == i] for i in range(len(classes))]\n",
    "#         preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(classes))]\n",
    "\n",
    "#         for i, (t, p) in enumerate(zip(gt, preds)):\n",
    "#             metrics = compute_metrics(p, t)\n",
    "#             scores[classes[i]].append(metrics['f1_score'])\n",
    "#     #         print(classes[i], metrics['f1_score'])\n",
    "#     #     print()\n",
    "#     #     if idx == 1:\n",
    "#     #         break\n",
    "#     for k, v in scores.items():\n",
    "#         print(f'{k} \\t Avg F1: {np.mean(v):.3f}  \\t Avg F1==1: {np.mean(np.array(v) == 1):.3f}')\n",
    "# #         break\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    if \"img_h\" not in df_test.columns:\n",
    "        shapes = []\n",
    "        for i in range(len(df_test)):\n",
    "            img = cv2.imread(df_test['path'][i])\n",
    "            shapes.append(img.shape[:2])\n",
    "        df_test['img_h'] = np.array(shapes)[:, 0]\n",
    "        df_test['img_w'] = np.array(shapes)[:, 1]\n",
    "\n",
    "    df_val = df_test\n",
    "    \n",
    "    df_target = pd.read_csv(\"../output/dot_labels.csv\")\n",
    "else:\n",
    "    df_val = df[df['split'] == \"val\"].reset_index(drop=True).head(100)\n",
    "    df_val['path'] = '../input/v2/images/valid/' + df_val['id'] + '.jpg'\n",
    "    df_val['gt_path'] = '../input/v2/labels/valid/' + df_val['id'] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\"dot\"]\n",
    "df_val = df_val[df_val['chart-type'].isin(TYPES)].reset_index(drop=True)\n",
    "# df_val = df_val[df_val['source'] == \"extracted\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(size=Config.size)\n",
    "dataset = InferenceDataset(df_val, transforms, pad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "meter, _ = predict(model, dataset, Config)\n",
    "\n",
    "# for i, p in enumerate(meter.preds):\n",
    "#     p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# transforms = get_transfos(size=Config.size)\n",
    "# dataset = InferenceDataset(df_val, transforms)\n",
    "\n",
    "# meter_2, _ = predict(model, dataset, Config)\n",
    "\n",
    "# for i, p in enumerate(meter.preds):\n",
    "#     p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR\n",
    "- split line ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "from util.boxes import expand_boxes\n",
    "from util.ocr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = \"microsoft/trocr-base-stage1\"\n",
    "\n",
    "# processor = TrOCRProcessor.from_pretrained(name)\n",
    "# ocr_model = VisionEncoderDecoderModel.from_pretrained(name).cuda()\n",
    "\n",
    "# try:\n",
    "#     ocr_model = ocr_model.cuda()\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHED_CLASSES = [\n",
    "    'x_title', 'y_title', 'plot_area', 'other', 'xlabel', 'ylabel',\n",
    "    'chart_title', 'x_tick', 'y_tick', 'legend_patch', 'legend_label',\n",
    "    'legend_title', 'legend_area', 'mark_label', 'value_label',\n",
    "    'y_axis_area', 'x_axis_area', 'tick_grouping'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None, pad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "df_preds = []\n",
    "for idx in range(len(dataset)):\n",
    "#     idx = 9\n",
    "#     DEBUG = True\n",
    "    \n",
    "    img, gt, shape = dataset[idx]\n",
    "\n",
    "    if img.shape[1] > img.shape[0] * 1.5:\n",
    "        padding = img.shape[0] // 2\n",
    "    else:\n",
    "        padding = 0\n",
    "    meter.preds[idx].update_shape((img.shape[0] + padding, img.shape[1]))\n",
    "\n",
    "    # Cached\n",
    "    cached_result = inference_detector(cached_model, dataset.paths[idx])  # list[array]\n",
    "    score_th = min(0.1, cached_result[4][2, 4])\n",
    "\n",
    "    if DEBUG:\n",
    "        for i, (r, c) in enumerate(zip(cached_result, CACHED_CLASSES)):\n",
    "            if c == \"plot_area\":\n",
    "                cached_result[i] = r[:1]\n",
    "            elif c not in ['plot_area', \"xlabel\"]:\n",
    "                cached_result[i] = np.empty((0, 5))\n",
    "\n",
    "        cached_model.show_result(\n",
    "            dataset.paths[idx],\n",
    "            cached_result,\n",
    "            out_file='../output/sample_result.jpg',\n",
    "            score_thr=score_th,\n",
    "            thickness=1,\n",
    "            font_size=5,\n",
    "        )\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        plt.imshow(cv2.imread('../output/sample_result.jpg'))\n",
    "        plt.axis(False)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    id_ = df_val.id[idx]\n",
    "\n",
    "    print(idx, id_[:10], end=\"\\t\")\n",
    "    title = f\"{id_} - {df_val.source[idx]} {df_val['chart-type'][idx]}\"\n",
    "\n",
    "    preds_ = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == 0] for i in range(1)][0]\n",
    "    \n",
    "    # too big\n",
    "    preds_ = preds_[(preds_[:, 2] - preds_[:, 0]) < 100]\n",
    "    preds_ = preds_[(preds_[:, 3] - preds_[:, 3]) < 100]\n",
    "    \n",
    "#     if not len(preds_):  # use bigger\n",
    "#         print('Swap')\n",
    "#         preds_ = [meter_2.preds[idx]['pascal_voc'][meter_2.labels[idx] == 0] for i in range(1)][0]\n",
    "#         # too big\n",
    "#         preds_ = preds_[(preds_[:, 2] - preds_[:, 0]) < 100]\n",
    "#         preds_ = preds_[(preds_[:, 3] - preds_[:, 3]) < 100]\n",
    "    \n",
    "    preds = [[], [], [], preds_]\n",
    "\n",
    "    # Override with cached\n",
    "   \n",
    "    preds[1] = cached_result[4][cached_result[4][:, -1] > score_th][:, :4].astype(int)\n",
    "    preds[0] = cached_result[2][:1, :4].astype(int)\n",
    "\n",
    "    if DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "        \n",
    "#     break\n",
    "    # TODO : VERIF\n",
    "    preds = post_process_preds_dots(preds, margin_pt=5, margin_text=5)\n",
    "#     preds[-1] = constraint_size(preds[-1], margin=2, coef=0.2)\n",
    "\n",
    "    margin = (img.shape[0] + img.shape[1]) / (2 * 20)\n",
    "    preds = restrict_labels_x(preds, margin=margin)\n",
    "\n",
    "    # Visual similarity\n",
    "    try:\n",
    "        retrieved_boxes = retrieve_missing_boxes(\n",
    "            preds, img, verbose=DEBUG, min_sim=0.8, seed=100, hw=None, max_retrieved=20, margin=-1\n",
    "        )\n",
    "        if len(retrieved_boxes):\n",
    "            print('RETRIEVED', len(retrieved_boxes), end=\"\\t\")\n",
    "            preds[-1] = np.concatenate([preds[-1], retrieved_boxes])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "    \n",
    "    try:\n",
    "        centers, clusters = cluster_on_x(preds[-1], shape[1], plot=DEBUG)\n",
    "        centers = np.array([c for i, c in enumerate(centers) if clusters[i] > 0])\n",
    "    except:\n",
    "        centers, clusters = None, None\n",
    "    \n",
    "#     print(clusters)\n",
    "#     print(centers)\n",
    "#     break\n",
    "\n",
    "    if len(preds[1]):\n",
    "        xlabels = preds[1]\n",
    "        xlabels_loc = (xlabels[:, 0] + xlabels[:, 2]) / 2\n",
    "\n",
    "        if centers is not None:\n",
    "            mapping, retrieved_xlabels = assign_dots(preds[1], centers, retrieve_missing=True)\n",
    "            if len(retrieved_xlabels):\n",
    "                xlabels = np.concatenate([xlabels, retrieved_xlabels])\n",
    "            xlabels_loc = (xlabels[:, 0] + xlabels[:, 2]) / 2\n",
    "\n",
    "            preds[1] = xlabels\n",
    "\n",
    "        if DEBUG:\n",
    "            print(centers, clusters)    \n",
    "            print(mapping, )\n",
    "\n",
    "    #     print('Target')\n",
    "    #     display(df_target[df_target['id'] == df_val.id[idx]][[\"x\", \"y\"]])\n",
    "\n",
    "        # OCR\n",
    "        x_texts = ocr(ocr_model, processor, img, preds[1], margin=1, plot=DEBUG)\n",
    "\n",
    "        xs, ys, locs = [], [], []\n",
    "        for i, txt in enumerate(x_texts):\n",
    "            if clusters is not None:\n",
    "                if i in mapping.keys():\n",
    "                    xs.append(txt)\n",
    "                    locs.append(xlabels_loc[i])\n",
    "                    ys.append(clusters.get(mapping[i], 0))\n",
    "                else:\n",
    "                    if xlabels_loc[i] > preds[0][0][0]:\n",
    "                        xs.append(txt)\n",
    "                        locs.append(xlabels_loc[i])\n",
    "                        ys.append(0)\n",
    "            else:\n",
    "                xs.append(txt)\n",
    "                locs.append(xlabels_loc[i])\n",
    "                ys.append(0)\n",
    "    else:\n",
    "        xs = [str(i) for i in range(len(centers))]\n",
    "        locs = centers\n",
    "        ys = list(clusters.values())\n",
    "\n",
    "    if PLOT:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "    \n",
    "    pred = pd.DataFrame({\"x\": xs, \"y\": np.array(ys).astype(int), \"loc\": locs})\n",
    "    pred = pred.sort_values('loc').reset_index(drop=True)\n",
    "\n",
    "    if df_target is not None:\n",
    "        gt = df_target[df_target['id'] == id_].reset_index(drop=True)\n",
    "        gt['y'] = gt[\"y\"].astype(int)\n",
    "\n",
    "        # TODO \n",
    "        score_x = score_series(gt['x'].values, pred['x'].values)\n",
    "        score_y = score_series(gt['y'].values, pred['y'].values)\n",
    "        print(f\"Scores  -  x: {score_x:.3f}  - y: {score_y:.3f}\")\n",
    "\n",
    "        scores += [score_x, score_y]\n",
    "#         display(pred)\n",
    "\n",
    "    if DEBUG and not TEST:\n",
    "        print('GT')\n",
    "        display(gt)\n",
    "\n",
    "    pred['id'] = id_\n",
    "    df_preds.append(pred)\n",
    "    if DEBUG: #  or TEST:\n",
    "        print('PRED')\n",
    "        display(pred)\n",
    "\n",
    "#     if idx >= 2:\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(scores):\n",
    "    print(f'Dots CV : {np.mean(scores) :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
