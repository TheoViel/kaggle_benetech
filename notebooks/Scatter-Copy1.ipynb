{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from inference.yolo import *\n",
    "from util.metrics import *\n",
    "\n",
    "from post_process.retrieve import retrieve_missing_boxes\n",
    "from post_process.reg import rounding, linear_regression\n",
    "from post_process.ticks import restrict_on_line, assign\n",
    "from post_process.in_graph import post_process_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df_train.csv')\n",
    "df_text = pd.read_csv('../input/texts.csv')\n",
    "df_target = pd.read_csv('../input/y_train.csv')\n",
    "df_elt = pd.read_csv('../input/elements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isin(ANOMALIES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv('../input/df_split.csv')\n",
    "df = df.merge(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "df = df[df['chart-type'].isin(CLASSES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigChart:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v2.5/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v6.6/weights/best.pt\"  # detect only labels & ticks\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v7./weights/best.pt\"  # detect only markers\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v4./weights/last.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v8./weights/best.pt\"\n",
    "    weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v8.2/weights/last.pt\"\n",
    "\n",
    "    version = \"v8\"\n",
    "    labels = ['chart', 'text', 'tick', 'point']\n",
    "    \n",
    "#     version = \"v6\n",
    "#     labels = ['chart', 'text', 'tick']\n",
    "    \n",
    "#     version = \"v7\"\n",
    "#     labels = [\"dots\"]\n",
    "\n",
    "#     size = (512, 512)\n",
    "    size = (640, 640)\n",
    "#     size = (1024, 1024)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = [0.1, 0.4, 0.2, 0.2]\n",
    "    iou_thresh = [0.5, 0.25, 0.25, 0.25]\n",
    "#     conf_thresh = [0.1, 0.4, 0.2, 0.001]\n",
    "#     iou_thresh = [0.5, 0.25, 0.25, 0.5]\n",
    "\n",
    "    max_per_img = 500\n",
    "    min_per_img = 0\n",
    "\n",
    "    val_bs = 16\n",
    "    device = \"cuda\"\n",
    "    \n",
    "config_chart = ConfigChart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(config_chart.weights), \"Weights do not exist\"\n",
    "model_chart = retrieve_model(config_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigMarker:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v2.5/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v6.6/weights/best.pt\"  # detect only labels & ticks\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v7./weights/best.pt\"  # detect only markers\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v4./weights/last.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v8./weights/best.pt\"\n",
    "    weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v8.2/weights/best.pt\"\n",
    "    \n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v7.20/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v7.21/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v10./weights/last.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v11./weights/last.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v11.5/weights/last.pt\"\n",
    "    version = \"v5\"\n",
    "    labels = ['chart', 'text', 'tick', 'point']\n",
    "    \n",
    "#     version = \"v6\"\n",
    "#     labels = ['chart', 'text', 'tick']\n",
    "    \n",
    "#     version = \"v11\"\n",
    "#     labels = [\"point\"]\n",
    "\n",
    "#     size = (512, 512)\n",
    "    size = (640, 640)\n",
    "#     size = (1024, 1024)\n",
    "\n",
    "    # NMS\n",
    "#     conf_thresh = 0.001  # [0.1, 0.4, 0.2, 0.2]\n",
    "#     iou_thresh = 0.5  # [0.5, 0.25, 0.25, 0.25]\n",
    "    \n",
    "    conf_thresh = [0.1, 0.4, 0.2, 0.2]\n",
    "    iou_thresh = [0.5, 0.25, 0.25, 0.25]\n",
    "    \n",
    "#     conf_thresh = [0.1, 0.4, 0.2, 0.001]\n",
    "#     iou_thresh = [0.5, 0.25, 0.25, 0.5]\n",
    "\n",
    "    max_per_img = 200\n",
    "    min_per_img = 0\n",
    "    \n",
    "    val_bs = 16\n",
    "    device = \"cuda\"\n",
    "    \n",
    "config_marker = ConfigMarker\n",
    "VERSION = config_marker.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(config_marker.weights), \"Weights do not exist\"\n",
    "model_marker = retrieve_model(config_marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_types = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "#     \"vertical_bar\",\n",
    "#     \"horizontal_bar\",\n",
    "    \"scatter\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.yolo import Model\n",
    "# model_marker = retrieve_model(\n",
    "#     config_marker,\n",
    "#     Model(\"../yolov7/cfg/training/yolov7-w6.yaml\", nc=len(config_marker.labels))\n",
    "# )\n",
    "\n",
    "# state_dict = torch.load(config_marker.weights)\n",
    "# state_dict = state_dict['model'].state_dict()\n",
    "\n",
    "# model_marker.model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split'] == \"val\"].reset_index(drop=True)  # .head(10)\n",
    "df_val['path'] = f'../input/{VERSION}/images/valid/' + df_val['id'] + '.jpg'\n",
    "df_val['gt_path'] = f'../input/{VERSION}/labels/valid/' + df_val['id'] + '.txt'\n",
    "df_val_ = df_val.copy()\n",
    "\n",
    "for t in chart_types:\n",
    "    print(f'\\n-> Chart type : {t}\\n')\n",
    "    df_val = df_val_[df_val_['chart-type'] == t].reset_index(drop=True)  # .head(8)\n",
    "\n",
    "    transforms = get_transfos(size=config_marker.size)\n",
    "    dataset = InferenceDataset(df_val, transforms)\n",
    "    \n",
    "    try:\n",
    "        meter, fts = predict(model_marker, dataset, config_marker)\n",
    "    except:\n",
    "        meter = predict(model_marker, dataset, config_marker)\n",
    "        \n",
    "    for i, p in enumerate(meter.preds):\n",
    "        p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))\n",
    "\n",
    "    f1s = {c: [] for c in config_marker.labels}\n",
    "    recalls = {c: [] for c in config_marker.labels}\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, gt, shape = dataset[idx]\n",
    "\n",
    "        gt = Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\")['pascal_voc']\n",
    "        gt = [gt[dataset.classes[idx] == i] for i in range(len(config_marker.labels))]\n",
    "        preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(config_marker.labels))]\n",
    "        \n",
    "#         preds = post_process_preds(preds)\n",
    "\n",
    "        for i, (t, p) in enumerate(zip(gt, preds)):\n",
    "            metrics = compute_metrics(p, t)\n",
    "            f1s[config_marker.labels[i]].append(metrics['f1_score'])\n",
    "            recalls[config_marker.labels[i]].append(metrics['recall'])\n",
    "\n",
    "    for k, v in f1s.items():\n",
    "        print(f'{k} \\t Avg F1: {np.mean(v):.3f}  \\t Avg F1==1: {np.mean(np.array(v) == 1):.3f}', end=\"\\t\")\n",
    "        print(f'Avg Recall==1: {np.mean(np.array(recalls[k]) == 1):.3f}')\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.001 - Avg F1: 0.699 - Avg Recall==1: 0.764\n",
    "- 0.010  - Avg F1: 0.842 - Avg Recall==1: 0.733"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "- IoU per class\n",
    "- merge xticks and yticks (/labels)\n",
    "- train without bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split'] == \"val\"].reset_index(drop=True)\n",
    "df_val['path'] = f'../input/{VERSION}/images/valid/' + df_val['id'] + '.jpg'\n",
    "df_val['gt_path'] = f'../input/{VERSION}/labels/valid/' + df_val['id'] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val  # .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "#     \"vertical_bar\",\n",
    "#     \"horizontal_bar\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "df_val = df_val[df_val['chart-type'].isin(TYPES)].reset_index(drop=True)\n",
    "# df_val = df_val[df_val['source'] == \"extracted\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(size=config_marker.size)\n",
    "dataset = InferenceDataset(df_val, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# meter_marker, fts = predict(model_marker, dataset, config_marker)\n",
    "meter_marker = predict(model_marker, dataset, config_marker)\n",
    "\n",
    "\n",
    "for i, p in enumerate(meter_marker.preds):\n",
    "    p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# meter_chart, _ = predict(model_chart, dataset, config_chart)\n",
    "meter_chart = predict(model_chart, dataset, config_chart)\n",
    "\n",
    "\n",
    "for i, p in enumerate(meter_chart.preds):\n",
    "    p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "from util.boxes import expand_boxes\n",
    "from util.ocr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"microsoft/trocr-base-stage1\"\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(name)\n",
    "ocr_model = VisionEncoderDecoderModel.from_pretrained(name).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main\n",
    "- Enforce sim between dets\n",
    "- conv sim not robust to col  (#26)\n",
    "- Make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = fts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = feats / ((feats ** 2).sum(0, keepdims=True) + 1e-6).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_sim = 0.7\n",
    "\n",
    "# sims = []\n",
    "# for box in preds[-1][:5]:\n",
    "# #     print(box)\n",
    "#     y = (box[0] + box[2]) / 2\n",
    "#     y = int(y / img.shape[1] * feats.size(2))\n",
    "#     x = (box[1] + box[3]) / 2\n",
    "#     x = int(x / img.shape[0] * feats.size(1))\n",
    "    \n",
    "# #     print(x, y)\n",
    "    \n",
    "# #     plt.imshow(img[box[1]: box[3], box[0]: box[2]])\n",
    "# #     plt.show()\n",
    "    \n",
    "#     vec = feats[:, x, y][:, None, None]\n",
    "    \n",
    "# #     sim = ((feats - vec) ** 2).mean(0, keepdims=True)\n",
    "# #     sim = 1 / (sim + 1)\n",
    "\n",
    "#     sim = (feats * vec).sum(0, keepdims=True)\n",
    "    \n",
    "# #     sim = torch.clamp(sim, torch.quantile(sim, 0.5) * 1.05, 1)\n",
    "# #     sim = (sim - sim.min()) / (sim.max() - sim.min())\n",
    "\n",
    "#     sim = torch.where(sim < min_sim, 0, sim)\n",
    "#     sims.append(sim)\n",
    "    \n",
    "# #     plt.imshow(sim[0].cpu().numpy())\n",
    "# #     plt.colorbar()\n",
    "# #     plt.show()\n",
    "    \n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx in range(len(dataset)):\n",
    "#     idx = 0\n",
    "#     if recalls['point'][idx] >= 1:\n",
    "#         continue\n",
    "#     idx = 0\n",
    "#     DEBUG = True\n",
    "    \n",
    "    img, gt, _ = dataset[idx]\n",
    "\n",
    "    id_ = df_val.id[idx]\n",
    "\n",
    "    print(idx, id_, end=\"\\t\")\n",
    "    title = f\"{id_} - {df_val.source[idx]} {df_val['chart-type'][idx]}\"\n",
    "    \n",
    "    preds = [\n",
    "        meter_chart.preds[idx]['pascal_voc'][meter_chart.labels[idx] == i]\n",
    "        for i in range(len(config_chart.labels))\n",
    "    ]\n",
    "    preds_marker = [\n",
    "        meter_marker.preds[idx]['pascal_voc'][meter_marker.labels[idx] == i]\n",
    "        for i in range(len(config_marker.labels))\n",
    "    ]\n",
    "    confidences_marker =  [\n",
    "        meter_marker.confidences[idx][meter_marker.labels[idx] == i]\n",
    "        for i in range(len(config_marker.labels))\n",
    "    ]\n",
    "    \n",
    "#     n = 10\n",
    "#     # Filter on size\n",
    "#     widths = preds[-1][:, 2] - preds[-1][:, 0]\n",
    "#     heights = preds[-1][:, 3] - preds[-1][:, 1]\n",
    "#     preds[-1] = preds[-1][\n",
    "#         (widths < widths[:5].mean() * 2) & (heights < heights[:5].mean() * 2)\n",
    "#     ]\n",
    "    \n",
    "#     preds[-1] = preds[-1][:n]\n",
    "#     confidences[-1] = confidences[-1][:n]\n",
    "\n",
    "#     plt.grid()\n",
    "#     for c in confidences:\n",
    "#         plt.plot(c, marker=\"x\", linewidth=0)\n",
    "#     plt.show()\n",
    "\n",
    "    if len(preds) == 4:  # Replace\n",
    "        preds[-1] = preds_marker[-1]\n",
    "    elif len(preds) == 3: # Append\n",
    "        preds.append(preds_marker[-1])\n",
    "        \n",
    "#     break\n",
    "#     plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "#     break\n",
    "\n",
    "    preds = post_process_preds(preds)\n",
    "    \n",
    "    if DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    margin = (img.shape[0] + img.shape[1]) / (2 * 20)\n",
    "    preds = restrict_on_line(preds, margin=margin)\n",
    "    \n",
    "    retrieved_boxes = retrieve_missing_boxes(preds, img, verbose=DEBUG)\n",
    "\n",
    "    if len(retrieved_boxes):\n",
    "        preds[-1] = np.concatenate([preds[-1], retrieved_boxes])\n",
    "        \n",
    "    if PLOT:\n",
    "#         preds[-1] = preds[-1][:5]\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    # OCR\n",
    "    x_texts = ocr(ocr_model, processor, img, preds[1], margin=1, plot=DEBUG)\n",
    "    x_values, x_errors = post_process_texts(x_texts)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"x labels :\", x_values, \" - errors:\", x_errors)\n",
    "#     print(x_values)\n",
    "#     print(preds[3])\n",
    "    \n",
    "    if len(preds[-1]):\n",
    "        reg_x = linear_regression(preds[3], x_values, x_errors, preds[-1], mode=\"x\", verbose=DEBUG)\n",
    "\n",
    "        y_texts = ocr(ocr_model, processor, img, preds[2], margin=3, plot=DEBUG)\n",
    "        y_values, y_errors = post_process_texts(y_texts)\n",
    "\n",
    "        if DEBUG:\n",
    "             print(\"y labels :\", y_values, \" - errors:\", y_errors)\n",
    "\n",
    "        reg_y = linear_regression(preds[4], y_values, y_errors, preds[-1], mode=\"y\", verbose=DEBUG)\n",
    "\n",
    "        gt = df_target[df_target['id'] == id_].reset_index(drop=True)\n",
    "        gt[[\"x\", \"y\"]] = gt[[\"x\", \"y\"]].astype(float)\n",
    "        gt = gt.sort_values(['x', 'y'], ignore_index=True)\n",
    "\n",
    "        reg_x = np.round(reg_x, rounding(np.max(reg_x)))\n",
    "        pred = pd.DataFrame({\"x\": reg_x, \"y\": reg_y})\n",
    "        pred = pred.sort_values(['x', 'y'], ignore_index=True)\n",
    "\n",
    "        score_x = score_series(gt['x'].values, pred['x'].values)\n",
    "        score_y = score_series(gt['y'].values, pred['y'].values)\n",
    "    else:\n",
    "        score_x, score_y = 0, 0\n",
    "\n",
    "    print(f\"Scores  -  x: {score_x:.3f}  - y: {score_y:.3f}\")\n",
    "    \n",
    "    scores += [score_x, score_y]\n",
    "    \n",
    "#     if score_x == 0 and score_y == 0:\n",
    "#         plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    if DEBUG:\n",
    "        print('GT')\n",
    "        display(gt)\n",
    "        print('PRED')\n",
    "        display(pred)\n",
    "\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Scatter CV : {np.mean(scores) :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
