{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from inference.yolo import *\n",
    "from util.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_preds(preds):\n",
    "    assert VERSION != \"v1\"\n",
    "    try:\n",
    "        graph = preds[0][0]\n",
    "    except:\n",
    "        return preds\n",
    "    \n",
    "    # Points are inside the graph\n",
    "    points = preds[3]\n",
    "    margin = 10\n",
    "    points = points[points[:, 0] > graph[0] - margin]\n",
    "    points = points[points[:, 1] > graph[1] - margin]\n",
    "    points = points[points[:, 2] < graph[2] + margin]\n",
    "    points = points[points[:, 3] < graph[3] + margin]\n",
    "    \n",
    "    # Texts are below or left of the graph\n",
    "    texts = preds[1]\n",
    "    margin = 30\n",
    "    texts = texts[\n",
    "        (texts[:, 1] > graph[3] - margin) |  # left\n",
    "        (texts[:, 0] < graph[0] + margin)    # bottom\n",
    "    ]\n",
    "#     texts = texts[\n",
    "#         ((texts[:, 2] < graph[0]) & (texts[:, 3] > graph[1]) & (texts[:, 1] < graph[3])) |  # left\n",
    "#         ((texts[:, 1] > graph[3]) & (texts[:, 2] > graph[0]) & (texts[:, 0] < graph[2]))    # bottom\n",
    "#     ]\n",
    "    \n",
    "    # Ticks are on the axis\n",
    "    ticks = preds[2]\n",
    "#     margin = 10\n",
    "#     ticks = ticks[\n",
    "#         ((np.abs((ticks[:, 2] + ticks[:, 2]) / 2 - graph[0]) < margin) & (ticks[:, 3] > graph[1]) & (ticks[:, 1] < graph[3])) |  # left\n",
    "#         ((np.abs((ticks[:, 1] + ticks[:, 3]) / 2 - graph[3]) < margin) & (ticks[:, 2] > graph[0]) & (ticks[:, 0] < graph[2]))    # bottom\n",
    "#     ]\n",
    "    \n",
    "    \n",
    "    return [preds[0], texts, ticks, points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_assignment(mat):\n",
    "    row_ind, col_ind = [], []\n",
    "    for i in range(np.min(mat.shape)):\n",
    "        row, col = np.unravel_index(np.argmin(mat), mat.shape)\n",
    "        mat[row] = np.inf\n",
    "        mat[:, col] = np.inf\n",
    "        row_ind.append(row)\n",
    "        col_ind.append(col)\n",
    "        \n",
    "    return row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign(ticks, labels, tol=2, mode=\"x\"):\n",
    "    if mode == \"x\":\n",
    "        labels_x, labels_y = (labels[:, 0] + labels[:, 2]) / 2, labels[:, 1]\n",
    "    else:\n",
    "        labels_x, labels_y = labels[:, 2], (labels[:, 1] + labels[:, 3]) / 2\n",
    "\n",
    "    labels_xy = np.stack([labels_x, labels_y], -1)\n",
    "#     print(labels_xy.shape)\n",
    "\n",
    "    ticks_x, ticks_y = (ticks[:, 0] + ticks[:, 2]) / 2, (ticks[:, 1] + ticks[:, 3]) / 2\n",
    "    ticks_xy = np.stack([ticks_x, ticks_y], -1)\n",
    "\n",
    "#     print(ticks_xy.shape)\n",
    "    \n",
    "    cost_matrix = np.sqrt(((ticks_xy[:, None] - labels_xy[None]) ** 2).sum(-1))\n",
    "    \n",
    "#     print(np.min(cost_matrix))\n",
    "    if mode == \"x\":  # penalize y_label < y_tick\n",
    "        cost_matrix += ((ticks_y[:, None] - labels_y[None]) > 0) * np.min(cost_matrix) * tol\n",
    "    else:  # penalize x_tick < x_label\n",
    "        cost_matrix += ((ticks_x[:, None] - labels_x[None]) < 0) * np.min(cost_matrix) * tol\n",
    "         \n",
    "    row_ind, col_ind = my_assignment(cost_matrix.copy())\n",
    "    \n",
    "#     print(row_ind, col_ind)\n",
    "    \n",
    "    ticks_assigned, labels_assigned = [], []\n",
    "\n",
    "    for tick_idx, label_idx in zip(row_ind, col_ind):\n",
    "#         print(cost_matrix[tick_idx, label_idx])\n",
    "        if cost_matrix[tick_idx, label_idx] < max(tol * 5, tol * np.min(cost_matrix)):\n",
    "            ticks_assigned.append(ticks[tick_idx])\n",
    "            labels_assigned.append(labels[label_idx])\n",
    "            \n",
    "    return np.array(ticks_assigned), np.array(labels_assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_on_line(preds, margin=5, cat=False):\n",
    "    try:\n",
    "        graph = preds[0][0]\n",
    "    except:\n",
    "        return preds\n",
    "    x_axis, y_axis = graph[0], graph[3]\n",
    "    \n",
    "    ticks = preds[2]\n",
    "    ticks_x, ticks_y = (ticks[:, 0] + ticks[:, 2]) / 2, (ticks[:, 1] + ticks[:, 3]) / 2\n",
    "    \n",
    "#     print(x_axis, y_axis)\n",
    "#     print(ticks_x)\n",
    "#     print(ticks_y)\n",
    "    \n",
    "    dists_x = ticks_x - x_axis\n",
    "    dists_y = ticks_y - y_axis\n",
    "    \n",
    "    best_x = dists_x[np.argmax([(np.abs(dists_x - d) < margin).sum() for d in dists_x])]\n",
    "    best_y = dists_y[np.argmax([(np.abs(dists_y - d) < margin).sum() for d in dists_y])]\n",
    "    \n",
    "#     print(dists_x - best_x)\n",
    "#     print(dists_y - best_y)\n",
    "    y_ticks = ticks[np.abs(dists_x - best_x) < margin]  # similar x\n",
    "    x_ticks = ticks[np.abs(dists_y - best_y) < margin]  # similar y\n",
    "    \n",
    "#     print(x_ticks)\n",
    "    \n",
    "    # Pair with labels\n",
    "    labels = preds[1]    \n",
    "    \n",
    "    x_ticks, x_labels = assign(x_ticks.copy(), labels.copy())\n",
    "    y_ticks, y_labels = assign(y_ticks.copy(), labels.copy(), mode=\"y\")\n",
    "    \n",
    "    # Reorder\n",
    "    order_x = np.argsort(x_ticks[:, 0])\n",
    "    x_ticks = x_ticks[order_x]\n",
    "    x_labels = x_labels[order_x]\n",
    "    \n",
    "    order_y = np.argsort(y_ticks[:, 1])[::-1]\n",
    "    y_ticks = y_ticks[order_y]\n",
    "    y_labels = y_labels[order_y]\n",
    "\n",
    "    if not cat:\n",
    "        return [preds[0], x_labels, y_labels, x_ticks, y_ticks, preds[3]]\n",
    "    \n",
    "    labels = np.unique(np.concatenate([x_labels, y_labels]), axis=0)\n",
    "    ticks = np.unique(np.concatenate([x_ticks, y_ticks]), axis=0)\n",
    "    \n",
    "    return [preds[0], labels, ticks, preds[3]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df_train.csv')\n",
    "df_text = pd.read_csv('../input/texts.csv')\n",
    "df_target = pd.read_csv('../input/y_train.csv')\n",
    "df_elt = pd.read_csv('../input/elements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isin(ANOMALIES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv('../input/df_split.csv')\n",
    "df = df.merge(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VERSION == \"v2\":\n",
    "    CLASSES = [\n",
    "        \"dot\",\n",
    "        \"line\",\n",
    "        \"scatter\",\n",
    "    ]\n",
    "\n",
    "    df = df[df['chart-type'].isin(CLASSES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "    weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v2.5/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-e6-v2./weights/best.pt\"\n",
    "\n",
    "#     size = (512, 512)\n",
    "    size = (640, 640)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = [0.1, 0.4, 0.2, 0.5]  # todo : per class\n",
    "    max_per_img = 500\n",
    "    min_per_img = 0\n",
    "    iou_thresh = [0.5, 0.25, 0.25, 0.75]\n",
    "\n",
    "    val_bs = 16\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrieve_model(Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_types = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "#     \"vertical_bar\",\n",
    "#     \"horizontal_bar\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "if VERSION == \"v1\":\n",
    "    classes = [\"x_text\", \"y_text\", \"x_tick\", \"y_tick\", \"point\", \"bar\"]\n",
    "else:\n",
    "    classes = ['chart', 'text', 'tick', 'point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split'] == \"val\"].reset_index(drop=True)\n",
    "df_val['path'] = f'../input/{VERSION}/images/valid/' + df_val['id'] + '.jpg'\n",
    "df_val['gt_path'] = f'../input/{VERSION}/labels/valid/' + df_val['id'] + '.txt'\n",
    "df_val_ = df_val.copy()\n",
    "\n",
    "for t in chart_types:\n",
    "    print(f'\\n-> Chart type : {t}\\n')\n",
    "    df_val = df_val_[df_val_['chart-type'] == t].reset_index(drop=True)\n",
    "\n",
    "    transforms = get_transfos(size=Config.size)\n",
    "    dataset = InferenceDataset(df_val, transforms)\n",
    "    \n",
    "    meter = predict(model, dataset, Config)\n",
    "    for i, p in enumerate(meter.preds):\n",
    "        p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))\n",
    "\n",
    "    scores = {c: [] for c in classes}\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, gt, shape = dataset[idx]\n",
    "\n",
    "        gt = Boxes(gt, (shape[0], shape[1]), bbox_format=\"yolo\")['pascal_voc']\n",
    "        gt = [gt[dataset.classes[idx] == i] for i in range(len(classes))]\n",
    "        preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(classes))]\n",
    "        \n",
    "        preds = post_process_preds(preds)\n",
    "\n",
    "        for i, (t, p) in enumerate(zip(gt, preds)):\n",
    "            metrics = compute_metrics(p, t)\n",
    "            scores[classes[i]].append(metrics['f1_score'])\n",
    "    #         print(classes[i], metrics['f1_score'])\n",
    "    #     print()\n",
    "    #     if idx == 1:\n",
    "    #         break\n",
    "    for k, v in scores.items():\n",
    "        print(f'{k} \\t Avg F1: {np.mean(v):.3f}  \\t Avg F1==1: {np.mean(np.array(v) == 1):.3f}')\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "- IoU per class\n",
    "- merge xticks and yticks (/labels)\n",
    "- train without bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df[df['split'] == \"val\"].reset_index(drop=True)\n",
    "df_val['path'] = '../input/v1/images/valid/' + df_val['id'] + '.jpg'\n",
    "df_val['gt_path'] = '../input/v1/labels/valid/' + df_val['id'] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "#     \"vertical_bar\",\n",
    "#     \"horizontal_bar\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "df_val = df_val[df_val['chart-type'].isin(TYPES)].reset_index(drop=True)\n",
    "# df_val = df_val[df_val['source'] == \"extracted\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(size=Config.size)\n",
    "dataset = InferenceDataset(df_val, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "meter = predict(model, dataset, Config)\n",
    "\n",
    "for i, p in enumerate(meter.preds):\n",
    "    p.update_shape((df_val['img_h'][i], df_val['img_w'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "from util.boxes import expand_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"microsoft/trocr-base-stage1\"\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(name)\n",
    "ocr_model = VisionEncoderDecoderModel.from_pretrained(name).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(model, processor, img, boxes, plot=False, margin=0):\n",
    "    inputs, crops = [], []\n",
    "    for box in boxes:\n",
    "#         if box[3] - box[1] < 5 and not margin:  # too small !\n",
    "#             margin = 1\n",
    "        y0, y1 = max(box[1] - margin, 0), min(img.shape[0], box[3] + margin)\n",
    "#         margin = 0\n",
    "        \n",
    "#         if box[2] - box[0] < 5 and not margin:  # too small !\n",
    "#             margin = 1\n",
    "        x0, x1 = max(box[0] - margin, 0), min(img.shape[1], box[2] + margin)\n",
    "#         margin = 0\n",
    "\n",
    "        crop = img[y0: y1, x0: x1]\n",
    "        crops.append(crop)\n",
    "        img_p = processor(crop, return_tensors=\"pt\").pixel_values.cuda()\n",
    "        inputs.append(img_p)\n",
    "\n",
    "    generated_ids = model.generate(torch.cat(inputs, 0))\n",
    "    generated_texts = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        for i, box in enumerate(boxes):\n",
    "            plt.subplot(1, len(boxes) , i + 1)\n",
    "            plt.imshow(crops[i])\n",
    "            plt.title(generated_texts[i])\n",
    "            plt.axis(False)\n",
    "        plt.show()\n",
    "        \n",
    "    return generated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def post_process_texts(texts):\n",
    "    \"\"\"\n",
    "    TODO : fractions, powers\n",
    "    B, M, K suffixes\n",
    "    \n",
    "    \"\"\"\n",
    "    values, errors = [], []\n",
    "    for i, t in enumerate(texts):\n",
    "        # Oo -> 0\n",
    "        t = re.sub('O', \"0\", t)\n",
    "        t = re.sub('o', \"0\", t)\n",
    "        t = re.sub('o', \"0\", t)\n",
    "        \n",
    "        # No numeric ?\n",
    "        if not any(c.isnumeric() for c in t):\n",
    "            errors.append(i)\n",
    "            continue\n",
    "\n",
    "        # Prefixes or suffixes \n",
    "        while not (t[0].isnumeric() or t[0] == \"-\" or t[0] == \".\"):\n",
    "            t = t[1:]\n",
    "            if not len(t):\n",
    "                break\n",
    "        if len(t):\n",
    "            while not t[-1].isnumeric():\n",
    "                t = t[:-1]\n",
    "\n",
    "        # Handle .,\n",
    "        if \",\" in t or \".\" in t:\n",
    "            if all([len(char) == 3 for char in t.split(',')][1:]):\n",
    "#                 print('rep ,')\n",
    "                t = re.sub('\\,', \"\", t)\n",
    "            if all([len(char) == 3 for char in t.split('.')][1:]):\n",
    "#                 print('rep .')\n",
    "                t = re.sub('\\.', \"\", t)\n",
    "\n",
    "        if len(t):\n",
    "            try:\n",
    "#                 print(float(t))\n",
    "                values.append(float(t))\n",
    "            except:\n",
    "    #             print(f\"Error with char {texts[i]}\")\n",
    "                errors.append(i)\n",
    "        else:\n",
    "            errors.append(i)\n",
    "    \n",
    "    assert len(values) + len(errors) == len(texts)\n",
    "    return np.array(values), errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(x_train, values, verbose=0):\n",
    "    corr_rank = np.abs(spearmanr(x_train, values).statistic)\n",
    "    \n",
    "    if corr_rank > 0.99:\n",
    "        return []\n",
    "    \n",
    "    # One outlier\n",
    "    for i in range(len(x_train)):\n",
    "        x_train_ = [x for j, x in enumerate(x_train) if j != i]\n",
    "        values_ = [v for j, v in enumerate(values) if j != i]\n",
    "        corr_rank = np.abs(spearmanr(x_train_, values_).statistic)\n",
    "        \n",
    "        if corr_rank > 0.99:\n",
    "            if verbose:\n",
    "                print(f'Remove {i}')\n",
    "            return [i]\n",
    "        \n",
    "    # Two outliers\n",
    "    for i in range(len(x_train)):\n",
    "        for i2 in range(i):\n",
    "            x_train_ = [x for j, x in enumerate(x_train) if (j != i and j != i2)]\n",
    "            values_ = [v for j, v in enumerate(values) if (j != i and j != i2)]\n",
    "            corr_rank = np.abs(spearmanr(x_train_, values_).statistic)\n",
    "\n",
    "            if corr_rank > 0.99:\n",
    "                if verbose:\n",
    "                    print(f'Remove {i}, {i2}')\n",
    "                return [i, i2]\n",
    "            \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_increasing_subset(lst):\n",
    "    n = len(lst)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    \n",
    "    # Initialize the lengths and previous indices\n",
    "    lengths = [1] * n\n",
    "    previous_indices = [-1] * n\n",
    "\n",
    "    # Iterate over the list and update the lengths and previous indices\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            if lst[i] > lst[j] and lengths[i] < lengths[j] + 1:\n",
    "                lengths[i] = lengths[j] + 1\n",
    "                previous_indices[i] = j\n",
    "    \n",
    "    # Find the index of the longest increasing subsequence\n",
    "    max_length_index = max(range(n), key=lambda x: lengths[x])\n",
    "\n",
    "    # Reconstruct the longest increasing subsequence\n",
    "    result = []\n",
    "    while max_length_index != -1:\n",
    "        result.append(lst[max_length_index])\n",
    "        max_length_index = previous_indices[max_length_index]\n",
    "    \n",
    "    return result[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_order(values, verbose=0):\n",
    "    ref = np.arange(len(values))\n",
    "    sort = np.argsort(values)\n",
    "    \n",
    "    # Correct order\n",
    "    if (ref == sort).all() or (ref[::-1] == sort).all():\n",
    "        return []\n",
    "    \n",
    "    longest_inc = longest_increasing_subset(sort)\n",
    "    longest_dec = longest_increasing_subset(sort[::-1])\n",
    "    \n",
    "#     print(longest_inc, longest_dec)\n",
    "    \n",
    "    if len(longest_inc) >= len(longest_dec):\n",
    "        return [i for i in sort if i not in longest_inc]\n",
    "    else:\n",
    "        return [i for i in sort if i not in longest_dec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def linear_regression(ticks, values, errors, points, mode=\"x\", verbose=0):\n",
    "    if len(np.unique(values)) == 1:\n",
    "        return [values[0] for _ in range(len(points))]\n",
    "    elif len(values) == 0:\n",
    "        return [0 for _ in range(len(points))]\n",
    "    \n",
    "    ticks = np.array([t for i, t in enumerate(ticks) if i not in errors])\n",
    "    \n",
    "    if mode == \"x\":\n",
    "        x_test = (points[:, 0] + points[:, 2]) / 2\n",
    "        x_train = (ticks[:, 0] + ticks[:, 2]) / 2\n",
    "    else:\n",
    "        x_test = (points[:, 1] + points[:, 3]) / 2\n",
    "        x_train = (ticks[:, 1] + ticks[:, 3]) / 2  \n",
    "\n",
    "    corr = np.abs(pearsonr(x_train, values).statistic)\n",
    "    corr_rank = np.abs(spearmanr(x_train, values).statistic)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Correlations before pp\", corr, corr_rank)\n",
    "    \n",
    "    outliers = find_outliers(x_train, values, verbose=verbose)\n",
    "    x_train = np.array([x for j, x in enumerate(x_train) if j not in outliers])\n",
    "    values = np.array([v for j, v in enumerate(values) if j not in outliers])\n",
    "    \n",
    "    outliers = find_outliers_order(values, verbose=verbose)\n",
    "    x_train = np.array([x for j, x in enumerate(x_train) if j not in outliers])\n",
    "    values = np.array([v for j, v in enumerate(values) if j not in outliers])\n",
    "    \n",
    "    corr = np.abs(pearsonr(x_train, values).statistic)\n",
    "    corr_rank = np.abs(spearmanr(x_train, values).statistic)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Correlations after pp\", corr, corr_rank)\n",
    "    \n",
    "    log = False\n",
    "    if corr > 0.99:\n",
    "        pass\n",
    "    else:\n",
    "        if corr_rank > 0.99 and np.min(values) > 0:\n",
    "            corr_log = np.abs(pearsonr(x_train, np.log(values)).statistic)\n",
    "            \n",
    "#             print(\"log\", corr_log)\n",
    "            if corr_log > 0.99:\n",
    "                log = True\n",
    "                values = np.log(values)\n",
    "                \n",
    "    model = LinearRegression()\n",
    "    \n",
    "    model.fit(x_train[:, None], values)\n",
    "    \n",
    "    pred = model.predict(x_test[:, None])\n",
    "    \n",
    "    if log:\n",
    "        pred = np.exp(pred)\n",
    "    \n",
    "#     print(x_test, pred)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding(x):\n",
    "    thresholds = [40, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.0001]\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        if x > threshold:\n",
    "            return i\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.exp(np.arange(-3, 3))\n",
    "# plt.plot(np.arange(-3, 3), x)\n",
    "# plt.yscale('log')\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx in range(len(dataset)):\n",
    "#     idx = 53\n",
    "    \n",
    "    img, gt, _ = dataset[idx]\n",
    "\n",
    "    id_ = df_val.id[idx]\n",
    "    \n",
    "    print(idx, id_, end=\"\\t\")\n",
    "    title = f\"{id_} - {df_val.source[idx]} {df_val['chart-type'][idx]}\"\n",
    "    \n",
    "    preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(classes))]\n",
    "    preds = post_process_preds(preds)\n",
    "    \n",
    "    if PLOT:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    margin = (img.shape[0] + img.shape[1]) / (2 * 20)\n",
    "    preds = restrict_on_line(preds, margin=margin)\n",
    "        \n",
    "    if PLOT:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "    \n",
    "#     break\n",
    "\n",
    "#     print('Target')\n",
    "#     display(df_target[df_target['id'] == df_val.id[idx]][[\"x\", \"y\"]])\n",
    "\n",
    "    # OCR\n",
    "    x_texts = ocr(ocr_model, processor, img, preds[1], margin=1, plot=PLOT)\n",
    "    x_values, x_errors = post_process_texts(x_texts)\n",
    "\n",
    "    if PLOT:\n",
    "        print(\"x labels :\", x_values, \" - errors:\", x_errors)\n",
    "#     print(x_values)\n",
    "#     print(preds[3])\n",
    "    \n",
    "    reg_x = linear_regression(preds[3], x_values, x_errors, preds[-1], mode=\"x\", verbose=PLOT)\n",
    "\n",
    "    y_texts = ocr(ocr_model, processor, img, preds[2], margin=3, plot=PLOT)\n",
    "    y_values, y_errors = post_process_texts(y_texts)\n",
    "\n",
    "    if PLOT:\n",
    "         print(\"y labels :\", y_values, \" - errors:\", y_errors)\n",
    "    \n",
    "    reg_y = linear_regression(preds[4], y_values, y_errors, preds[-1], mode=\"y\", verbose=PLOT)\n",
    "    \n",
    "    gt = df_target[df_target['id'] == id_].reset_index(drop=True)\n",
    "    gt[[\"x\", \"y\"]] = gt[[\"x\", \"y\"]].astype(float)\n",
    "    gt = gt.sort_values(['x', 'y'], ignore_index=True)\n",
    "    \n",
    "    reg_x = np.round(reg_x, rounding(np.max(reg_x)))\n",
    "    pred = pd.DataFrame({\"x\": reg_x, \"y\": reg_y})\n",
    "    pred = pred.sort_values(['x', 'y'], ignore_index=True)\n",
    "    \n",
    "    score_x = score_series(gt['x'].values, pred['x'].values)\n",
    "    score_y = score_series(gt['y'].values, pred['y'].values)\n",
    "\n",
    "    print(f\"Scores  -  x: {score_x:.3f}  - y: {score_y:.3f}\")\n",
    "    \n",
    "    scores += [score_x, score_y]\n",
    "\n",
    "    if PLOT:\n",
    "        print('GT')\n",
    "        display(gt)\n",
    "        print('PRED')\n",
    "        display(pred)\n",
    "\n",
    "#     if idx >= 10:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Scatter CV : {np.mean(scores) :.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
