{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from inference.yolo import *\n",
    "from util.metrics import *\n",
    "\n",
    "from post_process.retrieve import retrieve_missing_boxes\n",
    "from post_process.reg import rounding, linear_regression\n",
    "from post_process.ticks import restrict_on_line, assign\n",
    "from post_process.in_graph import post_process_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"dot\",\n",
    "    \"line\",\n",
    "    \"scatter\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../input/scatter/imgs/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"path\": images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['path'].apply(lambda x: x[:-4].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gt_path'] = \"../input/scatter/labels/\" + df['id'] + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['missing'] = df['gt_path'].apply(lambda x: not(os.path.exists(x)))\n",
    "# df['missing'].sum()\n",
    "\n",
    "# for img in tqdm(df[df['missing']]['path']):\n",
    "#     shutil.copyfile(img, \"../input/scatter/imgs_m/\" + img.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coords_path'] = df['path'].apply(lambda x: x[:-4] + \".csv\")\n",
    "\n",
    "# df['missing'] = df['coords_path'].apply(lambda x: not(os.path.exists(x)))\n",
    "# df['missing'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df.copy()  # .head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val.sort_values('id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "    weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v2.5/weights/best.pt\"\n",
    "#     weights = \"/workspace/kaggle_benetech/logs/yolov7x-e6-v2./weights/best.pt\"\n",
    "\n",
    "#     size = (512, 512)\n",
    "    size = (640, 640)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = [0.5, 0.2, 0.2, 0.5]  # todo : per class\n",
    "    max_per_img = 500\n",
    "    min_per_img = 0\n",
    "    iou_thresh = [0.5, 0.25, 0.25, 0.75]\n",
    "\n",
    "    val_bs = 16\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = retrieve_model(Config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['chart', 'text', 'tick', 'point']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transfos(size=Config.size)\n",
    "dataset = InferenceDataset(df_val, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# meter = predict(model, dataset, Config)\n",
    "\n",
    "# for i, p in enumerate(meter.preds):\n",
    "#     p.update_shape(tuple(dataset[i][-1][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('../input/scatter/preds/')\n",
    "# os.makedirs('../input/scatter/preds/')\n",
    "\n",
    "# with open(\"../input/scatter/preds/labels.txt\", 'w') as f:\n",
    "#     for c in classes:\n",
    "#         f.write(c)\n",
    "#         f.write('\\n')\n",
    "\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "# for idx in tqdm(range(len(dataset)), disable=PLOT):\n",
    "# #     idx = 94\n",
    "# #     PLOT = False\n",
    "\n",
    "#     img, gt, _ = dataset[idx]\n",
    "\n",
    "#     id_ = df_val.id[idx]\n",
    "\n",
    "# #     print(idx, id_, end=\"\\t\")\n",
    "#     title = f\"{id_}\"\n",
    "    \n",
    "#     preds = [meter.preds[idx]['pascal_voc'][meter.labels[idx] == i] for i in range(len(classes))]\n",
    "    \n",
    "#     if PLOT:\n",
    "#         plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "#     preds = [meter.preds[idx]['yolo'][meter.labels[idx] == i] for i in range(len(classes))]\n",
    "        \n",
    "#     file_name = re.sub(\"/imgs/\", \"/preds/\", df_val['path'][idx][:-4]) + \".txt\"\n",
    "#     with open(file_name, 'w') as f:\n",
    "#         for c, boxes_c in enumerate(preds):\n",
    "#             for box in boxes_c:\n",
    "#                 if c in [0, 3]:\n",
    "#                     continue\n",
    "#                 str_bbox = ' '.join([str(c)] + [f\"{b:.4g}\" for b in box])\n",
    "#                 f.write(str_bbox)\n",
    "#                 f.write('\\n')\n",
    "                \n",
    "#                 if c == 0:\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.utils.logging.set_verbosity_error()\n",
    "\n",
    "from transformers import TrOCRProcessor\n",
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "from util.boxes import expand_boxes\n",
    "from util.ocr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"microsoft/trocr-base-stage1\"\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(name)\n",
    "ocr_model = VisionEncoderDecoderModel.from_pretrained(name).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrict_on_line(preds, margin_x=5, margin_y=5, cat=False):\n",
    "    try:\n",
    "        graph = preds[0][0]\n",
    "        x_axis, y_axis = graph[0], graph[3]\n",
    "    except Exception:\n",
    "        x_axis, y_axis = 0, 0\n",
    "    \n",
    "    for i in [2, 1]:\n",
    "#         print(i)\n",
    "        ticks = preds[i]\n",
    "        if i == 2:\n",
    "            ticks_x, ticks_y = (ticks[:, 0] + ticks[:, 2]) / 2, (ticks[:, 1] + ticks[:, 3]) / 2\n",
    "        else:\n",
    "            ticks_x, ticks_y = ticks[:, 2], ticks[:, 1]\n",
    "\n",
    "        dists_x = ticks_x - x_axis\n",
    "        dists_y = ticks_y - y_axis\n",
    "        \n",
    "        ys = []\n",
    "        margin_x_ = margin_x\n",
    "        while len(ys) < 2 and margin_x < 100:\n",
    "            best_x = dists_x[np.argmax([(np.abs(dists_x - d) < margin_x_).sum() for d in dists_x])]\n",
    "            ys = ticks[np.abs(dists_x - best_x) < margin_x_] \n",
    "            margin_x_ += 1\n",
    "            \n",
    "        xs = []\n",
    "        margin_y_ = margin_y\n",
    "        while len(xs) < 2 and margin_y_ < 100:\n",
    "            best_y = dists_y[np.argmax([(np.abs(dists_y - d) < margin_y_).sum() for d in dists_y])]\n",
    "            xs = ticks[np.abs(dists_y - best_y) < margin_y]\n",
    "            margin_y_ += 1\n",
    "\n",
    "        if i == 1:\n",
    "            y_labels = ys.copy()\n",
    "            x_labels = xs.copy()\n",
    "        else:\n",
    "            y_ticks = ys.copy()\n",
    "            x_ticks = xs.copy()\n",
    "            \n",
    "    return [preds[0], x_labels, y_labels, x_ticks, y_ticks, preds[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "def my_assignment(mat):\n",
    "    row_ind, col_ind = [], []\n",
    "    for i in range(np.min(mat.shape)):\n",
    "        row, col = np.unravel_index(np.argmin(mat), mat.shape)\n",
    "        mat[row] = np.inf\n",
    "        mat[:, col] = np.inf\n",
    "        row_ind.append(row)\n",
    "        col_ind.append(col)\n",
    "\n",
    "    return row_ind, col_ind\n",
    "\n",
    "\n",
    "def assign(ticks, labels, tol=10, mode=\"x\", retrieve_missing=False, verbose=0):\n",
    "    if mode == \"x\":\n",
    "        labels_x, labels_y = (labels[:, 0] + labels[:, 2]) / 2, labels[:, 1]\n",
    "    else:\n",
    "        labels_x, labels_y = labels[:, 2], (labels[:, 1] + labels[:, 3]) / 2\n",
    "\n",
    "    labels_xy = np.stack([labels_x, labels_y], -1)\n",
    "    #     print(labels_xy.shape)\n",
    "\n",
    "    ticks_x, ticks_y = (ticks[:, 0] + ticks[:, 2]) / 2, (ticks[:, 1] + ticks[:, 3]) / 2\n",
    "    ticks_xy = np.stack([ticks_x, ticks_y], -1)\n",
    "\n",
    "    #     print(ticks_xy.shape)\n",
    "\n",
    "    cost_matrix = np.sqrt(((ticks_xy[:, None] - labels_xy[None]) ** 2).sum(-1))\n",
    "\n",
    "    #     print(np.min(cost_matrix))\n",
    "    if mode == \"x\":  # penalize y_label < y_tick\n",
    "        cost_matrix += (\n",
    "            ((ticks_y[:, None] - labels_y[None]) > 0) * np.min(cost_matrix) * tol\n",
    "        )\n",
    "    else:  # penalize x_tick < x_label\n",
    "        cost_matrix += (\n",
    "            ((ticks_x[:, None] - labels_x[None]) < 0) * np.min(cost_matrix) * tol\n",
    "        )\n",
    "\n",
    "    row_ind, col_ind = my_assignment(cost_matrix.copy())\n",
    "\n",
    "    #     print(row_ind, col_ind)\n",
    "\n",
    "    ticks_assigned, labels_assigned = [], []\n",
    "    assigned_label_ids = []\n",
    "\n",
    "    for tick_idx, label_idx in zip(row_ind, col_ind):\n",
    "        if cost_matrix[tick_idx, label_idx] < max(tol * 5, tol * np.min(cost_matrix)):\n",
    "            ticks_assigned.append(ticks[tick_idx])\n",
    "            assigned_label_ids.append(label_idx)\n",
    "            labels_assigned.append(labels[label_idx])\n",
    "            \n",
    "    if not retrieve_missing or not (len(labels) - len(assigned_label_ids)):\n",
    "        return np.array(ticks_assigned), np.array(labels_assigned)\n",
    "    \n",
    "    ticks_assigned = np.array(ticks_assigned)\n",
    "    labels_assigned = np.array(labels_assigned)\n",
    "    \n",
    "    unassigned = np.array(labels[[i for i in range(len(labels)) if i not in assigned_label_ids]])\n",
    "    if verbose:\n",
    "        print(\"Retrieve \", len(unassigned), mode)\n",
    "\n",
    "    if mode == \"x\":\n",
    "        x_test = (unassigned[:, 0] + unassigned[:, 2]) / 2\n",
    "        x_train = (labels_assigned[:, 0] + labels_assigned[:, 2]) / 2\n",
    "        y_train = (ticks_assigned[:, 0] + ticks_assigned[:, 2]) / 2\n",
    "    else:\n",
    "        x_test = (unassigned[:, 1] + unassigned[:, 3]) / 2\n",
    "        x_train = (labels_assigned[:, 1] + labels_assigned[:, 3]) / 2\n",
    "        y_train = (ticks_assigned[:, 1] + ticks_assigned[:, 3]) / 2\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train[:, None], y_train)\n",
    "    pred = model.predict(x_test[:, None])[:, None]\n",
    "    \n",
    "#     print(x_train, y_train)\n",
    "#     print(x_test, pred)\n",
    "\n",
    "    # Average ticks\n",
    "    xc = ((ticks_assigned[:, 0] + ticks_assigned[:, 2]) / 2).mean(0, keepdims=True)[None].repeat(len(pred), 0)\n",
    "    yc = ((ticks_assigned[:, 1] + ticks_assigned[:, 3]) / 2).mean(0, keepdims=True)[None].repeat(len(pred), 0)\n",
    "    w = (ticks_assigned[:, 2] - ticks_assigned[:, 0]).mean(0, keepdims=True)[None].repeat(len(pred), 0)\n",
    "    h = (ticks_assigned[:, 3] - ticks_assigned[:, 1]).mean(0, keepdims=True)[None].repeat(len(pred), 0)\n",
    "\n",
    "    # Replace with preds\n",
    "    if mode == \"x\":\n",
    "        xc = pred\n",
    "    else:\n",
    "        yc = pred\n",
    "\n",
    "    retrieved = np.concatenate([xc - w // 2, yc - h // 2, xc + w // 2, yc + h // 2], 1).astype(int)\n",
    "    ticks_assigned = np.concatenate([ticks_assigned, retrieved])\n",
    "    labels_assigned = np.concatenate([labels_assigned, unassigned])\n",
    "\n",
    "    return np.array(ticks_assigned), np.array(labels_assigned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_reorder(preds, x_ticks, x_labels, y_ticks, y_labels, cat=False):\n",
    "        \n",
    "    # Reorder\n",
    "    order_x = np.argsort(x_ticks[:, 0])\n",
    "    x_ticks = x_ticks[order_x]\n",
    "    x_labels = x_labels[order_x]\n",
    "\n",
    "    order_y = np.argsort(y_ticks[:, 1])[::-1]\n",
    "    y_ticks = y_ticks[order_y]\n",
    "    y_labels = y_labels[order_y]\n",
    "\n",
    "    if not cat:\n",
    "        return [preds[0], x_labels, y_labels, x_ticks, y_ticks, preds[-1]]\n",
    "\n",
    "    labels = np.unique(np.concatenate([x_labels, y_labels]), axis=0)\n",
    "    ticks = np.unique(np.concatenate([x_ticks, y_ticks]), axis=0)\n",
    "\n",
    "    return [preds[0], labels, ticks, preds[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_chart(x_ticks, y_ticks):\n",
    "    x_min = np.min(x_ticks[:, 0])\n",
    "    x_max = np.max(x_ticks[:, 2])\n",
    "    y_min = np.min(y_ticks[:, 1])\n",
    "    y_max = np.max(y_ticks[:, 3])\n",
    "    \n",
    "    return np.array([[x_min, y_min, x_max, y_max]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from post_process.outliers import find_outliers, find_outliers_order\n",
    "\n",
    "\n",
    "def linear_regression(ticks, values, errors, points, mode=\"x\", verbose=0):\n",
    "    warning = False\n",
    "    if len(np.unique(values)) == 1:\n",
    "        print('Warning, 1 ticks on axis', mode)\n",
    "        return [values[0] for _ in range(len(points))], True\n",
    "    elif len(values) == 0:\n",
    "        print('Warning, 0 ticks on axis', mode)\n",
    "        return [0 for _ in range(len(points))], True\n",
    "\n",
    "    ticks = np.array([t for i, t in enumerate(ticks) if i not in errors])\n",
    "\n",
    "    if mode == \"x\":\n",
    "        y_train = (ticks[:, 0] + ticks[:, 2]) / 2\n",
    "    else:\n",
    "        y_train = (ticks[:, 1] + ticks[:, 3]) / 2\n",
    "\n",
    "    corr = np.abs(pearsonr(y_train, values).statistic)\n",
    "    corr_rank = np.abs(spearmanr(y_train, values).statistic)\n",
    "    \n",
    "    if corr < 0.9999:\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Correlations before pp\", corr, corr_rank)\n",
    "\n",
    "        outliers = find_outliers(y_train, values, verbose=verbose, corr=\"pearson\", th=0.9999)\n",
    "        y_train = np.array([x for j, x in enumerate(y_train) if j not in outliers])\n",
    "        values = np.array([v for j, v in enumerate(values) if j not in outliers])\n",
    "\n",
    "        outliers = find_outliers_order(values, verbose=verbose)\n",
    "        y_train = np.array([x for j, x in enumerate(y_train) if j not in outliers])\n",
    "        values = np.array([v for j, v in enumerate(values) if j not in outliers])\n",
    "\n",
    "        corr = np.abs(pearsonr(y_train, values).statistic)\n",
    "        corr_rank = np.abs(spearmanr(y_train, values).statistic)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Correlations after pp\", corr, corr_rank)\n",
    "\n",
    "    if corr < 0.9999:\n",
    "        print(f'Warning, corr={corr:.4f}')\n",
    "        warning = True\n",
    "        \n",
    "    if len(np.unique(values)) <= 1 or len(np.unique(y_train)) <= 1:\n",
    "        print(f'Warning, not enough unique values')\n",
    "        warning = True\n",
    "        \n",
    "    print(\"train\", values, y_train, corr)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(values[:, None], y_train)\n",
    "    pred = model.predict(points)\n",
    "\n",
    "    return pred, warning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('../input/scatter/preds_final/')\n",
    "# os.makedirs('../input/scatter/preds_final/')\n",
    "\n",
    "# with open(\"../input/scatter/preds_final/labels.txt\", 'w') as f:\n",
    "#     for c in classes:\n",
    "#         f.write(c)\n",
    "#         f.write('\\n')\n",
    "\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "DEBUG = True\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx in tqdm(range(len(dataset)), disable=True):\n",
    "    idx = 4\n",
    "    DEBUG = True\n",
    "\n",
    "    img, gt, shape = dataset[idx]\n",
    "\n",
    "    id_ = df_val.id[idx]\n",
    "    title = f\"{id_}\"\n",
    "    \n",
    "    print(\"\\n\", idx, id_, end=\"\\t\")\n",
    "    \n",
    "    preds = [gt[dataset.classes[idx] == i] for i in range(len(classes))]\n",
    "    preds = [Boxes(p, shape)['pascal_voc'] for p in preds]\n",
    "    \n",
    "    if DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "        \n",
    "    margin_x = img.shape[1] / 50\n",
    "    margin_y = img.shape[0] / 50\n",
    "    preds = restrict_on_line(preds, margin_x=margin_x, margin_y=margin_y)\n",
    "    \n",
    "    if DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "    \n",
    "    x_ticks, x_labels = assign(preds[3].copy(), preds[1].copy(), retrieve_missing=True, verbose=DEBUG,)\n",
    "    y_ticks, y_labels = assign(preds[4].copy(), preds[2].copy(), retrieve_missing=True, verbose=DEBUG, mode=\"y\")\n",
    "    \n",
    "    preds = update_and_reorder(preds, x_ticks, x_labels, y_ticks, y_labels)\n",
    "    \n",
    "#     if PLOT:\n",
    "#         plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    coords = pd.read_csv(df_val['coords_path'][idx], header=None).values\n",
    "\n",
    "    x_texts = ocr(ocr_model, processor, img, preds[1], margin=1, plot=False)\n",
    "    x_values, x_errors = post_process_texts(x_texts)\n",
    "    if DEBUG:\n",
    "        print(\"x_labels\", x_values)\n",
    "    reg_x, warn_x = linear_regression(preds[3], x_values, x_errors, coords[:, :1], mode=\"x\", verbose=0)\n",
    "    \n",
    "    if warn_x:\n",
    "        continue\n",
    "    \n",
    "    y_texts = ocr(ocr_model, processor, img, preds[2], margin=1, plot=False)\n",
    "    y_values, y_errors = post_process_texts(y_texts)\n",
    "    if DEBUG:\n",
    "        print(\"y_labels\", y_values)\n",
    "    reg_y, warn_y = linear_regression(preds[4], y_values, y_errors, coords[:, 1:], mode=\"y\", verbose=0)\n",
    "    \n",
    "    if warn_y:\n",
    "        continue\n",
    "\n",
    "    hw = 8\n",
    "    preds[-1] = np.concatenate(\n",
    "        [reg_x[:, None] - hw, reg_y[:, None] - hw, reg_x[:, None] + hw, reg_y[:, None] + hw],\n",
    "        axis=1\n",
    "    ).astype(int)\n",
    "    \n",
    "    preds[0] = approx_chart(preds[3], preds[4])\n",
    "    \n",
    "    if PLOT or DEBUG:\n",
    "        plot_results(img, preds, figsize=(12, 7), title=title)\n",
    "\n",
    "    if warn_y or warn_x:\n",
    "        continue\n",
    "        \n",
    "    if SAVE:\n",
    "        file_name = re.sub(\"/imgs/\", \"/preds_final/\", df_val['path'][idx][:-4]) + \".txt\"\n",
    "        with open(file_name, 'w') as f:\n",
    "            for c, boxes_c in enumerate(preds):\n",
    "                boxes_c = Boxes(boxes_c, shape, bbox_format=\"pascal_voc\")[\"yolo\"]\n",
    "                for box in boxes_c:\n",
    "                    str_bbox = ' '.join([str(c)] + [f\"{b:.4g}\" for b in box])\n",
    "                    f.write(str_bbox)\n",
    "                    f.write('\\n')\n",
    "                    if c == 0:\n",
    "                        break\n",
    "        \n",
    "    # TODO: convert to yolo and save\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save lower dim images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = albu.Compose([\n",
    "    albu.LongestMaxSize(512, always_apply=True),\n",
    "    albu.ImageCompression(quality_lower=50, quality_upper=90, always_apply=True),\n",
    "#     albu.Resize(640, 640, always_apply=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['gt_path'] = df_val['gt_path'].apply(lambda x: re.sub(\"/labels/\", \"/preds_final/\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = InferenceDataset(df_val, None)\n",
    "dataset = InferenceDataset(df_val, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    shutil.rmtree('../input/scatter/imgs_r/')\n",
    "    os.makedirs('../input/scatter/imgs_r/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = pd.read_csv('../input/scatter/anomalies.csv', header=None)[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx in tqdm(range(len(dataset)), disable=False):\n",
    "    img_name = df_val['path'].values[idx]\n",
    "    label_name = re.sub(\"/imgs/\", \"/preds_final/\", img_name[:-4]) + \".txt\"\n",
    "\n",
    "    if img_name.split('/')[-1] in anomalies:\n",
    "        if os.path.exists(label_name):\n",
    "            os.remove(label_name)\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(label_name):\n",
    "        continue\n",
    "\n",
    "    img, gt, shape = dataset[idx]\n",
    "    \n",
    "#     preds = [gt[dataset.classes[idx] == i] for i in range(6)]\n",
    "#     preds = [Boxes(p, shape)['pascal_voc'] for p in preds]\n",
    "#     plot_results(\n",
    "#         img,\n",
    "#         preds,\n",
    "#         figsize=(12, 7),\n",
    "#         title=title,\n",
    "#         save_file=\"\",  # re.sub(\"/imgs/\", \"/imgs_r/\",df_val['path'].values[idx]),\n",
    "#         show=True\n",
    "#     )\n",
    "\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis(False)\n",
    "#     plt.show()\n",
    "    \n",
    "    if SAVE:\n",
    "        cv2.imwrite(re.sub(\"/imgs/\", \"/imgs_r/\", df_val['path'].values[idx]), img)\n",
    "        \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(\"../input/scatter/imgs_r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.exp(np.arange(-3, 3))\n",
    "# plt.plot(np.arange(-3, 3), x)\n",
    "# plt.yscale('log')\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['path'] = df_final['path'].apply(lambda x: re.sub(\"/imgs/\", \"/imgs_r/\", x))\n",
    "df_final = df_final[df_final['path'].apply(os.path.exists)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['gt_path'] = df_final['gt_path'].apply(lambda x: re.sub(\"/preds_final/\", \"/preds_final_2/\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generated {len(df_final)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InferenceDataset(df_final, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in tqdm(range(len(dataset)), disable=False):\n",
    "    img_name = df_val['path'].values[idx]\n",
    "\n",
    "    img, gt, shape = dataset[idx]\n",
    "    \n",
    "    preds = [gt[dataset.classes[idx] == i] for i in range(4)]\n",
    "    preds = [Boxes(p, shape)['pascal_voc'] for p in preds]\n",
    "    plot_results(\n",
    "        img,\n",
    "        preds,\n",
    "        figsize=(12, 7),\n",
    "        title=title,\n",
    "        save_file=\"\",  # re.sub(\"/imgs/\", \"/imgs_r/\",df_val['path'].values[idx]),\n",
    "        show=True\n",
    "    )\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx in tqdm(range(len(dataset)), disable=False):\n",
    "    img, gt, shape = dataset[idx]\n",
    "    \n",
    "    preds = [gt[dataset.classes[idx] == i] for i in range(6)]\n",
    "#     preds = [Boxes(p, shape)['yolo'] for p in preds]\n",
    "    \n",
    "    preds = [\n",
    "        preds[0],\n",
    "        np.concatenate([preds[1], preds[2]]),\n",
    "        np.concatenate([preds[3], preds[4]]),\n",
    "        preds[5],\n",
    "    ]\n",
    "\n",
    "#     plot_results(\n",
    "#         img,\n",
    "#         preds,\n",
    "#         figsize=(12, 7),\n",
    "#         title=title,\n",
    "#         save_file=\"\",  # re.sub(\"/imgs/\", \"/imgs_r/\", df_final['path'].values[idx]),\n",
    "#         show=True\n",
    "#     )\n",
    "\n",
    "    if SAVE:\n",
    "        file_name = re.sub(\"/imgs_r/\", \"/preds_final_2/\", df_final['path'][idx][:-4]) + \".txt\"\n",
    "#         print(file_name)\n",
    "        with open(file_name, 'w') as f:\n",
    "            written = []\n",
    "            for c, boxes_c in enumerate(preds):\n",
    "#                 boxes_c = Boxes(boxes_c, shape, bbox_format=\"pascal_voc\")[\"yolo\"]\n",
    "                for box in boxes_c:\n",
    "                    str_bbox = ' '.join([str(c)] + [f\"{b:.4g}\" for b in box])\n",
    "                    if str_bbox not in written:\n",
    "                        f.write(str_bbox)\n",
    "                        f.write('\\n')\n",
    "                        written.append(str_bbox)\n",
    "\n",
    "        \n",
    "    # TODO: convert to yolo and save\n",
    "#     if DEBUG:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
