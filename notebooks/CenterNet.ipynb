{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "\n",
    "from util.plots import *\n",
    "from util.metrics import *\n",
    "from util.torch import seed_everything\n",
    "from util.boxes import Boxes\n",
    "\n",
    "from model_zoo.centernet import CenterNet\n",
    "from data.dataset import CenterNetDataset\n",
    "from data.transforms import get_transfos_centernet\n",
    "from data.preparation import prepare_centernet_data\n",
    "\n",
    "from training.losses import CenterLoss\n",
    "\n",
    "from util.torch import init_distributed\n",
    "from util.logger import (\n",
    "    prepare_log_folder,\n",
    "    save_config,\n",
    "    create_logger,\n",
    "    init_neptune\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_val = prepare_centernet_data(use_extra=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfos = get_transfos_centernet(resize=(512, 512), strength=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CenterNetDataset(df_val, transfos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.random.choice(np.arange(len(dataset)), 1):\n",
    "    img, tgt, _ = dataset[idx]\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(img[0].cpu().numpy(), cmap=\"gray\")\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(img[1].cpu().numpy(), cmap=\"gray\")\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(tgt[:, :, 0].cpu().numpy(), interpolation=None)\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(tgt[:, :, 1].cpu().numpy(), interpolation=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CenterNet(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CenterLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(y, tgt.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    device = \"cuda\"https://smp.readthedocs.io/en/latest/index.html\n",
    "    save_weights = True\n",
    "\n",
    "    # Images\n",
    "    img_folder = \"v13_sim/\"\n",
    "    data_path = \"../input/\"\n",
    "    aug_strength = 1\n",
    "    resize = (512, 512)\n",
    "    use_extra = False\n",
    "\n",
    "    # k-fold\n",
    "    k = 4\n",
    "    folds_file = None\n",
    "    selected_folds = [0]\n",
    "\n",
    "    # Model\n",
    "    name = \"resnet18\"  # \"eca_nfnet_l2\"  # \"tf_efficientnetv2_s\" \"eca_nfnet_l1\"\n",
    "    pretrained_weights = None\n",
    "    num_classes = 3\n",
    "    n_channels = 3\n",
    "    drop_rate = 0.\n",
    "    drop_path_rate = 0.\n",
    "    syncbn = False\n",
    "\n",
    "    # Training\n",
    "    loss_config = {\n",
    "        \"name\": \"centerloss\",  # bce ?\n",
    "        \"smoothing\": 0.0,\n",
    "        \"activation\": \"\",\n",
    "        \"aux_loss_weight\": 0.,\n",
    "    }\n",
    "\n",
    "    data_config = {\n",
    "        \"batch_size\": 16,\n",
    "        \"val_bs\": 32,\n",
    "        \"mix\": \"cutmix\",\n",
    "        \"mix_proba\": 0,\n",
    "        \"mix_alpha\": 4.0,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"additive_mix\": False,\n",
    "    }\n",
    "\n",
    "    optimizer_config = {\n",
    "        \"name\": \"Ranger\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"warmup_prop\": 0.1,\n",
    "        \"betas\": (0.9, 0.999),\n",
    "        \"max_grad_norm\": 10.0,\n",
    "        \"weight_decay\": 0,  # 1e-2,\n",
    "    }\n",
    "\n",
    "    epochs = 10\n",
    "    use_fp16 = True\n",
    "\n",
    "    verbose = 1\n",
    "    verbose_eval = 200\n",
    "\n",
    "    fullfit = False\n",
    "    n_fullfit = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "log_folder = None\n",
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.main_centernet import k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f\"Logging results to {log_folder}\")\n",
    "    config_df = save_config(Config, log_folder + \"config.json\")\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "#     run = init_neptune(Config, log_folder)\n",
    "\n",
    "config = Config\n",
    "init_distributed(config)\n",
    "\n",
    "preds = k_fold(config, log_folder=log_folder, run=run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from util.centernet import process_and_score, pred2box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('../logs/2023-06-06/11/pred_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = process_and_score(preds.astype(np.float32), df_val, th=0.4, pool_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Avg F1: {np.mean(f1s):.3f}  \\t Avg F1==1: {np.mean(np.array(f1s) == 1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Avg F1: {np.mean(f1s):.3f}  \\t Avg F1==1: {np.mean(np.array(f1s) == 1):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.load('../logs/2023-06-06/11/pred_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "df_val['path'] = df_val['path'].apply(lambda x: re.sub('v13_sim/', \"v13/\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = 3\n",
    "pool = torch.nn.MaxPool2d(pool_size, stride=1, padding=pool_size // 2)\n",
    "\n",
    "shape = (128, 128)\n",
    "th = 0.4\n",
    "\n",
    "dataset = CenterNetDataset(df_val, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = False\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "for i in range(len(df_val)):\n",
    "#     i = 0\n",
    "#     DEBUG = True\n",
    "    \n",
    "    gt_path = df_val['gt_path'][i]\n",
    "    coords = open(gt_path, 'r').readlines()\n",
    "    coords = np.array([c[2:-1].split(' ') for c in coords]).astype(float)\n",
    "    \n",
    "    heatmap = torch.from_numpy(preds[i][0]).float()\n",
    "    sz = heatmap.size(-1)\n",
    "    \n",
    "#     if DEBUG:\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "    \n",
    "    reg = torch.ones_like(heatmap) * 0.005\n",
    "    reg = torch.stack([reg, reg])\n",
    "\n",
    "    heatmap = heatmap.unsqueeze(0).unsqueeze(0)\n",
    "    heatmap = torch.where(heatmap == pool(heatmap), heatmap, 0)\n",
    "    heatmap = heatmap[0, 0]\n",
    "    \n",
    "#     if DEBUG:\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "    \n",
    "    boxes, confs = pred2box(heatmap, reg, th)\n",
    "\n",
    "    if len(boxes):\n",
    "        boxes[:, 2] = coords[:, 2].max() * sz\n",
    "        boxes[:, 3] = coords[:, 3].max() * sz\n",
    "\n",
    "    pred_boxes = Boxes(boxes / sz, shape, bbox_format=\"yolo\")\n",
    "    gt_boxes = Boxes(coords, shape, bbox_format=\"yolo\")\n",
    "\n",
    "    metrics = compute_metrics([pred_boxes], [gt_boxes])\n",
    "    f1s.append(metrics['f1_score'])\n",
    "    \n",
    "#     print(i, df_val['id'][i], \"\\t f1==1\", metrics['f1_score'] == 1)\n",
    "    \n",
    "    if PLOT:\n",
    "        img, _, _ = dataset[i]\n",
    "        \n",
    "        pred_boxes.update_shape(img.shape)\n",
    "        gt_boxes.update_shape(img.shape)\n",
    "\n",
    "        plot_results(img, [[], [], [], pred_boxes['pascal_voc']])\n",
    "#         plot_results(img, [[], [], [], gt_boxes['pascal_voc']])\n",
    "\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.plots import plot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Avg F1: {np.mean(f1s):.3f}  \\t Avg F1==1: {np.mean(np.array(f1s) == 1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap > th)\n",
    "plt.scatter(boxes[:, 0], boxes[:, 1], s=1, c=\"r\")\n",
    "plt.scatter(coords[:, 0] * 128, coords[:, 1] * 128, s=1, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.5\n",
    "\n",
    "boxes, confs = pred2box(heatmap, reg, th)\n",
    "\n",
    "plt.imshow(heatmap > th)\n",
    "plt.scatter(boxes[:, 0], boxes[:, 1], s=1, c=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "df_test = pd.DataFrame({\"path\": glob.glob('../input/dots/*')})\n",
    "df_test['id'] = df_test['path'].apply(lambda x: Path(x).stem)\n",
    "df_test['source'] = \"extracted\"\n",
    "df_test['chart-type'] = \"dot\"\n",
    "df_test['gt_path'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.main_centernet import kfold_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = kfold_inference(df_test, '../logs/2023-06-06/12/')\n",
    "# pred_test = kfold_inference(df_test, '../logs/2023-06-06/14/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = 3\n",
    "pool = torch.nn.MaxPool2d(pool_size, stride=1, padding=pool_size // 2)\n",
    "\n",
    "shape = (128, 128)\n",
    "th = 0.5\n",
    "\n",
    "dataset = CenterNetDataset(df_test, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = []\n",
    "for i in range(len(dataset)):\n",
    "    \n",
    "    heatmap = torch.from_numpy(pred_test[i][0]).float()\n",
    "    heatmap = heatmap / heatmap.max()\n",
    "\n",
    "    sz = heatmap.size(-1)\n",
    "#     if DEBUG:\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "    \n",
    "    reg = torch.ones_like(heatmap) * 0.005\n",
    "    reg = torch.stack([reg, reg])\n",
    "\n",
    "    heatmap = heatmap.unsqueeze(0).unsqueeze(0)\n",
    "    heatmap = torch.where(heatmap == pool(heatmap), heatmap, 0)\n",
    "    heatmap = heatmap[0, 0]\n",
    "    \n",
    "#     if DEBUG:\n",
    "#         plt.imshow(heatmap)\n",
    "#         plt.show()\n",
    "    \n",
    "    boxes, confs = pred2box(heatmap, reg, th)\n",
    "\n",
    "    pred_boxes = Boxes(boxes / sz, shape, bbox_format=\"yolo\")\n",
    "    \n",
    "    print(i, df_val['id'][i])\n",
    "    \n",
    "    if PLOT:\n",
    "        img, _, _ = dataset[i]\n",
    "        pred_boxes.update_shape(img.shape)\n",
    "        plot_results(img, [[], [], [], pred_boxes['pascal_voc']])\n",
    "#         plot_results(img, [[], [], [], gt_boxes['pascal_voc']])\n",
    "\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
