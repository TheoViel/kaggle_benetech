{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About** : This notebook is used to train detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext nb_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from util.plots import *\n",
    "from inference.yolox import retrieve_yolox_model, predict, YoloXWrapper\n",
    "from inference.utils import get_transfos, InferenceDataset\n",
    "from util.metrics import *\n",
    "\n",
    "from post_process.similarity import extract_similarities\n",
    "from post_process.ticks import restrict_on_line, assign\n",
    "from post_process.in_graph import post_process_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/df_train.csv')\n",
    "df_text = pd.read_csv('../input/texts.csv')\n",
    "df_target = pd.read_csv('../input/y_train.csv')\n",
    "df_elt = pd.read_csv('../input/elements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['id'].isin(ANOMALIES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = pd.read_csv('../input/df_split.csv')\n",
    "df = df.merge(df_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "#     \"dot\",\n",
    "#     \"line\",\n",
    "    \"scatter\",\n",
    "]\n",
    "\n",
    "df = df[df['chart-type'].isin(CLASSES)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigMarker:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "\n",
    "    weights = \"/workspace/kaggle_benetech/logs/yolov7x-w6-v8.2/weights/best.pt\"\n",
    "\n",
    "    version = \"v5\"\n",
    "    labels = ['chart', 'text', 'tick', 'point']\n",
    "    \n",
    "    size = (640, 640)\n",
    "\n",
    "    \n",
    "    conf_thresh = [0.1, 0.4, 0.2, 0.1]\n",
    "    iou_thresh = [0.5, 0.25, 0.25, 0.1]\n",
    "\n",
    "\n",
    "    max_per_img = 500\n",
    "    min_per_img = 1\n",
    "    \n",
    "    val_bs = 16\n",
    "    device = \"cuda\"\n",
    "    \n",
    "config_marker = ConfigMarker\n",
    "VERSION = config_marker.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert os.path.exists(config_marker.weights), \"Weights do not exist\"\n",
    "# model_marker = retrieve_model(config_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigMarker:\n",
    "    selected_model = \"yolo\"\n",
    "    bbox_format = \"yolo\"\n",
    "    pred_format = \"pascal_voc\"\n",
    "    \n",
    "    name = \"benetech_1_m_1\"\n",
    "    \n",
    "#     version = \"v11_sim\"\n",
    "    version = \"v13\"\n",
    "    labels = [\"point\"]\n",
    "\n",
    "    size = (1024, 1024)\n",
    "\n",
    "    # NMS\n",
    "    conf_thresh = 0.4\n",
    "    iou_thresh = 0.2\n",
    "    max_per_img = 500\n",
    "    min_per_img = 1\n",
    "    \n",
    "    val_bs = 1  # if size[0] > 1024 else 16\n",
    "    device = \"cuda\"\n",
    "    \n",
    "config_marker = ConfigMarker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_marker = retrieve_yolox_model(config_marker.name)\n",
    "model_marker = YoloXWrapper(model_marker, config_marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOLDER = \"../output/weights/det_1/\"\n",
    "# name = config_marker.weights.split('/')[-3]\n",
    "\n",
    "# cp = torch.load(config_marker.weights)\n",
    "\n",
    "# import yaml\n",
    "# with open(FOLDER + name + '_cfg.yml', 'w') as outfile:\n",
    "#     yaml.dump(cp['model'].yaml, outfile)\n",
    "    \n",
    "# from util.torch import save_model_weights\n",
    "# torch.save(cp['model'].state_dict(), FOLDER + name + \"_weights.pt\")\n",
    "\n",
    "# print('-> Saved config to', FOLDER + name + '_cfg.yml')\n",
    "# print('-> Saved weight to', FOLDER + name + '_weights.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = \"v13\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# df = pd.DataFrame({\"path\": glob.glob('../input/dots/*')})\n",
    "# df['id'] = df['path'].apply(lambda x: Path(x).stem)\n",
    "# df['source'] = \"extracted\"\n",
    "# df['chart-type'] = \"dot\"\n",
    "# df['gt_path'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = pd.DataFrame({\"path\": glob.glob(f'../input/{VERSION}/images/*/*.jpg')})\n",
    "\n",
    "# df = pd.DataFrame({\"path\": glob.glob(f'../input/{VERSION}/val2017/*.jpg')})\n",
    "# df['id'] = df['path'].apply(lambda x: x[:-4].split('/')[-1])\n",
    "# df['gt_path'] = f'../input/{VERSION}/labels/valid/' + df['id'] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"path\": glob.glob(f'../input/{VERSION}/train2017/*.jpg')})\n",
    "# df['id'] = df['path'].apply(lambda x: x[:-4].split('/')[-1])\n",
    "# df['gt_path'] = f'../input/{VERSION}/labels/train/' + df['id'] + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT = True\n",
    "DEBUG = False\n",
    "SAVE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.arange(len(df))\n",
    "\n",
    "chunk_size = 100\n",
    "chunks = [ids[i: i + chunk_size] for i in range(0, len(ids), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SAVE:\n",
    "#     SAVE_FOLDER = f\"../input/{VERSION}_sim/\"\n",
    "#     os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "\n",
    "#     os.makedirs(SAVE_FOLDER + \"train2017/\", exist_ok=True)\n",
    "#     os.makedirs(SAVE_FOLDER + \"val2017/\", exist_ok=True)\n",
    "\n",
    "#     os.makedirs(SAVE_FOLDER + \"labels/\", exist_ok=True)\n",
    "#     _ = copy_tree(f\"../input/{VERSION}/labels/train\", f\"../input/{VERSION}_sim/labels/train\")\n",
    "#     _ = copy_tree(f\"../input/{VERSION}/labels/valid\", f\"../input/{VERSION}_sim/labels/valid\")\n",
    "#     _ = copy_tree(f\"../input/{VERSION}/annotations\", f\"../input/{VERSION}_sim/annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in tqdm(enumerate(chunks), total=len(chunks)):\n",
    "    \n",
    "    df_val = df.iloc[chunk].reset_index(drop=True)\n",
    "    \n",
    "    if DEBUG:\n",
    "        df_val = df_val.head(1)\n",
    "\n",
    "    transforms = get_transfos(size=config_marker.size)\n",
    "    dataset = InferenceDataset(df_val, transforms)\n",
    "    \n",
    "    meter_marker, fts = predict(model_marker, dataset, config_marker, extract_fts=True)\n",
    "    \n",
    "    dataset = InferenceDataset(df_val, None)\n",
    "    \n",
    "    scores = []\n",
    "    for idx in range(len(dataset)):\n",
    "        img, gt, shape = dataset[idx]\n",
    "\n",
    "        preds = meter_marker.preds[idx]\n",
    "        preds.update_shape(shape)\n",
    "\n",
    "        preds = [\n",
    "            preds['pascal_voc'][meter_marker.labels[idx] == i]\n",
    "            for i in range(len(config_marker.labels))\n",
    "        ]\n",
    "\n",
    "#         preds = post_process_preds(preds)\n",
    "\n",
    "#     #     break\n",
    "#         if PLOT:\n",
    "#             plot_results(img, [[], [], [], preds[-1]], figsize=(12, 7))\n",
    "# #     #     break\n",
    "        try:\n",
    "            sim_img = extract_similarities(fts[idx], preds, img, verbose=0)\n",
    "        except Exception:\n",
    "            print('Error extracting similarities')\n",
    "            sim_img = np.zeros(img.shape)\n",
    "\n",
    "        img_final = np.concatenate([\n",
    "            img.mean(-1, keepdims=True),\n",
    "            (1 - sim_img[:, :, :2]) * 255\n",
    "        ],-1).astype(np.uint8)\n",
    "        \n",
    "        if SAVE:\n",
    "            cv2.imwrite(\n",
    "                re.sub(f'/{VERSION}/', f'/{VERSION}_sim/', df_val['path'][idx]),\n",
    "                img_final\n",
    "            )\n",
    "\n",
    "        if PLOT or DEBUG or np.random.random() < 0.001:\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(sim_img)\n",
    "            plt.axis(False)\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(img)\n",
    "            plt.axis(False)\n",
    "            plt.show()\n",
    "            \n",
    "#             plt.figure(figsize=(15, 7))\n",
    "#             plt.imshow(img_final)\n",
    "#             plt.show()\n",
    "\n",
    "        if DEBUG:\n",
    "            break\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f7241b2af102f7e024509099765066b36197b195077f7bfac6e5bc041ba17c8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
